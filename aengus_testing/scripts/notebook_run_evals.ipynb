{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aengusl/.venv/hp-unlrn/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curent wd: /ext_usb/Desktop/mats/hp-unlrn/aengus_testing/scripts\n",
      "new wd: /ext_usb/Desktop/mats/hp-unlrn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.64s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "import datasets\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "# print current directory\n",
    "print(f\"curent wd: {os.getcwd()}\")\n",
    "os.chdir('../..')\n",
    "print(f\"new wd: {os.getcwd()}\")\n",
    "from tasks.hp.HPSAQ import HPSAQ\n",
    "\n",
    "# might need to adapt to quantize for 24gb 3090, or remove .cuda()\n",
    "hp_model = AutoModelForCausalLM.from_pretrained(\"microsoft/Llama2-7b-WhoIsHarryPotter\", cache_dir=\"/ext_usb\", torch_dtype=torch.bfloat16)\n",
    "regular_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", cache_dir=\"/ext_usb\", torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Llama2-7b-WhoIsHarryPotter\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def clear_gpu(model):\n",
    "    model.cpu()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "getting scores for hp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aengusl/.venv/hp-unlrn/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to temp/Tue-Jan30-0127.jsonl\n",
      "Book 1, scores: {'zero_shot': 0.3333333333333333, 'few_shot': 0.0975609756097561, 'unrelated_few_shot': 0.06666666666666667}\n",
      "Saved results to temp/Tue-Jan30-0128.jsonl\n",
      "Book 2, scores: {'zero_shot': 0.3148148148148148, 'few_shot': 0.14, 'unrelated_few_shot': 0.16666666666666666}\n",
      "Saved results to temp/Tue-Jan30-0129.jsonl\n",
      "Book 3, scores: {'zero_shot': 0.41379310344827586, 'few_shot': 0.25925925925925924, 'unrelated_few_shot': 0.2413793103448276}\n",
      "Saved results to temp/Tue-Jan30-0131.jsonl\n",
      "Book 4, scores: {'zero_shot': 0.48148148148148145, 'few_shot': 0.2, 'unrelated_few_shot': 0.24074074074074073}\n",
      "Saved results to temp/Tue-Jan30-0132.jsonl\n",
      "Book 5, scores: {'zero_shot': 0.7358490566037735, 'few_shot': 0.1836734693877551, 'unrelated_few_shot': 0.16981132075471697}\n",
      "Saved results to temp/Tue-Jan30-0134.jsonl\n",
      "Book 6, scores: {'zero_shot': 0.5833333333333334, 'few_shot': 0.3181818181818182, 'unrelated_few_shot': 0.16666666666666666}\n",
      "Saved results to temp/Tue-Jan30-0135.jsonl\n",
      "Book 7, scores: {'zero_shot': 0.6595744680851063, 'few_shot': 0.27906976744186046, 'unrelated_few_shot': 0.19148936170212766}\n",
      "\n",
      "\n",
      "\n",
      "getting scores for regular\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aengusl/.venv/hp-unlrn/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to temp/Tue-Jan30-0136.jsonl\n",
      "Book 1, scores: {'zero_shot': 0.26666666666666666, 'few_shot': 0.21951219512195122, 'unrelated_few_shot': 0.15555555555555556}\n",
      "Saved results to temp/Tue-Jan30-0138.jsonl\n",
      "Book 2, scores: {'zero_shot': 0.3333333333333333, 'few_shot': 0.26, 'unrelated_few_shot': 0.25925925925925924}\n",
      "Saved results to temp/Tue-Jan30-0139.jsonl\n",
      "Book 3, scores: {'zero_shot': 0.3448275862068966, 'few_shot': 0.3148148148148148, 'unrelated_few_shot': 0.3448275862068966}\n",
      "Saved results to temp/Tue-Jan30-0140.jsonl\n",
      "Book 4, scores: {'zero_shot': 0.46296296296296297, 'few_shot': 0.32, 'unrelated_few_shot': 0.3148148148148148}\n",
      "Saved results to temp/Tue-Jan30-0142.jsonl\n",
      "Book 5, scores: {'zero_shot': 0.6037735849056604, 'few_shot': 0.32653061224489793, 'unrelated_few_shot': 0.39622641509433965}\n",
      "Saved results to temp/Tue-Jan30-0143.jsonl\n",
      "Book 6, scores: {'zero_shot': 0.6666666666666666, 'few_shot': 0.4772727272727273, 'unrelated_few_shot': 0.3125}\n",
      "Saved results to temp/Tue-Jan30-0145.jsonl\n",
      "Book 7, scores: {'zero_shot': 0.48936170212765956, 'few_shot': 0.3488372093023256, 'unrelated_few_shot': 0.3191489361702128}\n"
     ]
    }
   ],
   "source": [
    "from tasks.hp.HPSAQ import HPSAQTranchedByBook\n",
    "import json\n",
    "\n",
    "hp_task = HPSAQTranchedByBook(book_idx=1)\n",
    "def clear_all():\n",
    "    clear_gpu(regular_model)\n",
    "    clear_gpu(hp_model)\n",
    "\n",
    "clear_all()\n",
    "\n",
    "# hp_task.generate_responses(hp_model.cuda(), tokenizer, eval_onthe_fly=True, eval_model='gpt-3.5-turbo', verbose=False)\n",
    "# hp_scores = hp_task.get_accuracies()\n",
    "# print(f\"hp scores: {hp_scores}\")\n",
    "# clear_all()\n",
    "\n",
    "# hp_task.generate_responses(regular_model.cuda(), tokenizer, eval_onthe_fly=True, eval_model='gpt-3.5-turbo', verbose=False)\n",
    "# regular_scores = hp_task.get_accuracies()\n",
    "# print(f\"regular scores: {regular_scores}\")\n",
    "\n",
    "def get_scores_for_all_books(model):\n",
    "\n",
    "    scores = []\n",
    "    for book_idx in range(1,8):\n",
    "        hp_task = HPSAQTranchedByBook(book_idx=book_idx)\n",
    "        hp_task.generate_responses(model.cuda(), tokenizer, eval_onthe_fly=True, eval_model='gpt-3.5-turbo', verbose=False)\n",
    "        scores.append(hp_task.get_accuracies())\n",
    "        print(f\"Book {book_idx}, scores: {scores[-1]}\")\n",
    "    return scores\n",
    "\n",
    "clear_all()\n",
    "print(\"\\n\\n\\ngetting scores for hp\")\n",
    "hp_scores = get_scores_for_all_books(hp_model)\n",
    "clear_all()\n",
    "print(\"\\n\\n\\ngetting scores for regular\")\n",
    "regular_scores = get_scores_for_all_books(regular_model)\n",
    "\n",
    "\n",
    "with open(\"tranched_scores.jsonl\", \"w\") as f:\n",
    "    for hp_score, regular_score in zip(hp_scores, regular_scores):\n",
    "        f.write(json.dumps({\"hp\": hp_score, \"regular\": regular_score}))\n",
    "        f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/ext_usb/Desktop/mats/hp-unlrn/aengus_testing/tranched_scores.jsonl\", \"r\") as f:\n",
    "    scores = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "books = {}\n",
    "for i, score in enumerate(scores):\n",
    "    books[i+1] = score\n",
    "\n",
    "with open(\"/ext_usb/Desktop/mats/hp-unlrn/aengus_testing/3tranched_scores.jsonl\", \"w\") as f:\n",
    "    f.write(json.dumps(books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Provided data\n",
    "# data = {\n",
    "#     \"1\": {\n",
    "#         \"hp\": {\"zero_shot\": 0.3111111111111111, \"few_shot\": 0.12195121951219512, \"unrelated_few_shot\": 0.13333333333333333},\n",
    "#         \"regular\": {\"zero_shot\": 0.26666666666666666, \"few_shot\": 0.21951219512195122, \"unrelated_few_shot\": 0.24444444444444444}\n",
    "#     },\n",
    "#     \"2\": {\n",
    "#         \"hp\": {\"zero_shot\": 0.3148148148148148, \"few_shot\": 0.18, \"unrelated_few_shot\": 0.2037037037037037},\n",
    "#         \"regular\": {\"zero_shot\": 0.24074074074074073, \"few_shot\": 0.32, \"unrelated_few_shot\": 0.2777777777777778}\n",
    "#     }\n",
    "# }\n",
    "data = {\"1\": {\"hp\": {\"zero_shot\": 0.3111111111111111, \"few_shot\": 0.12195121951219512, \"unrelated_few_shot\": 0.13333333333333333}, \"regular\": {\"zero_shot\": 0.26666666666666666, \"few_shot\": 0.21951219512195122, \"unrelated_few_shot\": 0.24444444444444444}}, \"2\": {\"hp\": {\"zero_shot\": 0.3148148148148148, \"few_shot\": 0.18, \"unrelated_few_shot\": 0.2037037037037037}, \"regular\": {\"zero_shot\": 0.24074074074074073, \"few_shot\": 0.32, \"unrelated_few_shot\": 0.2777777777777778}}, \"3\": {\"hp\": {\"zero_shot\": 0.3275862068965517, \"few_shot\": 0.2777777777777778, \"unrelated_few_shot\": 0.2413793103448276}, \"regular\": {\"zero_shot\": 0.3793103448275862, \"few_shot\": 0.35185185185185186, \"unrelated_few_shot\": 0.29310344827586204}}, \"4\": {\"hp\": {\"zero_shot\": 0.4444444444444444, \"few_shot\": 0.26, \"unrelated_few_shot\": 0.3148148148148148}, \"regular\": {\"zero_shot\": 0.42592592592592593, \"few_shot\": 0.34, \"unrelated_few_shot\": 0.3333333333333333}}, \"5\": {\"hp\": {\"zero_shot\": 0.6415094339622641, \"few_shot\": 0.32653061224489793, \"unrelated_few_shot\": 0.22641509433962265}, \"regular\": {\"zero_shot\": 0.5849056603773585, \"few_shot\": 0.4897959183673469, \"unrelated_few_shot\": 0.4716981132075472}}, \"6\": {\"hp\": {\"zero_shot\": 0.5, \"few_shot\": 0.29545454545454547, \"unrelated_few_shot\": 0.1875}, \"regular\": {\"zero_shot\": 0.5416666666666666, \"few_shot\": 0.4090909090909091, \"unrelated_few_shot\": 0.3125}}, \"7\": {\"hp\": {\"zero_shot\": 0.5957446808510638, \"few_shot\": 0.23255813953488372, \"unrelated_few_shot\": 0.2553191489361702}, \"regular\": {\"zero_shot\": 0.3191489361702128, \"few_shot\": 0.3488372093023256, \"unrelated_few_shot\": 0.3191489361702128}}}\n",
    "# Extracting categories and subcategories\n",
    "categories = list(data[\"1\"].keys())\n",
    "subcategories = list(data[\"1\"][categories[0]].keys())\n",
    "\n",
    "# Creating the plot with dictionary labels on x-axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Setting bar width\n",
    "bar_width = 0.2\n",
    "\n",
    "# Colors for each category\n",
    "colors = {'hp': 'red', 'regular': 'blue'}\n",
    "\n",
    "# Creating bars with colors and adjusting x-ticks for dictionary labels\n",
    "for i, (dict_key, dict_data) in enumerate(data.items()):\n",
    "    # Offset to separate each dictionary's data\n",
    "    offset = len(subcategories) * (len(categories) + 1) * bar_width\n",
    "    \n",
    "    for j, category in enumerate(categories):\n",
    "        # Extracting values for each subcategory in the current category\n",
    "        values = [dict_data[category][sub] for sub in subcategories]\n",
    "\n",
    "        # Position of bars for this category within the current dictionary\n",
    "        positions = np.arange(len(subcategories)) * bar_width * len(categories) + offset * i + bar_width * j\n",
    "\n",
    "        ax.bar(positions, values, bar_width, label=f'{category}', color=colors[category])\n",
    "\n",
    "# Adding labels and title\n",
    "ax.set_xlabel('Harry Potter Book (Zero, Few, Unrelated)')\n",
    "ax.set_ylabel('Values')\n",
    "ax.set_title('SAQ on book specific trivia\\nHP red, Regular blue')\n",
    "\n",
    "# Setting the x-axis ticks and labels for dictionaries\n",
    "dict_labels = [f'Book {dict_key}' for dict_key in data.keys()]\n",
    "dict_positions = np.arange(len(dict_labels)) * offset + bar_width * len(categories) / 2\n",
    "ax.set_xticks(dict_positions)\n",
    "ax.set_xticklabels(dict_labels)\n",
    "# ax.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ext_usb/Desktop/mats/hp-unlrn\n",
      "/ext_usb/Desktop/mats/hp-unlrn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.81s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('/ext_usb/Desktop/mats/hp-unlrn/')\n",
    "print(os.getcwd())\n",
    "from tasks.hp.HPFamiliarity import HPCompletionsFamiliarity\n",
    "from datetime import datetime\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "def clear_all():\n",
    "    clear_gpu(regular_model)\n",
    "    clear_gpu(hp_model)\n",
    "\n",
    "# might need to adapt to quantize for 24gb 3090, or remove .cuda()\n",
    "hp_model = AutoModelForCausalLM.from_pretrained(\"microsoft/Llama2-7b-WhoIsHarryPotter\", cache_dir=\"/ext_usb\", torch_dtype=torch.bfloat16)\n",
    "regular_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", cache_dir=\"/ext_usb\", torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Llama2-7b-WhoIsHarryPotter\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]/home/aengusl/.venv/hp-unlrn/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/aengusl/.venv/hp-unlrn/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 20/20 [00:18<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.25\n",
      "defaultdict(<class 'int'>, {'1': 2, '3': 13, '0': 5})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def clear_gpu(model):\n",
    "    model.cpu()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def clear_all():\n",
    "    clear_gpu(regular_model)\n",
    "    clear_gpu(hp_model)\n",
    "\n",
    "clear_all()\n",
    "\n",
    "hp_familiarity_task = HPCompletionsFamiliarity(dataset_path='tasks/hp/data/msr_data/evaluation_prompts_short.json')\n",
    "\n",
    "exp_time = datetime.now().strftime(\"%a-%b%-d-%H%M\")\n",
    "save_path = f'aengus_testing/datasets/llama-short-familiarity-completions-evaluated-{exp_time}.jsonl'\n",
    "\n",
    "hp_familiarity_task.generate_responses(regular_model.cuda(), tokenizer, save_path=save_path, eval_onthe_fly=True, eval_model='gpt-4-turbo-preview', max_new_tokens=20, temperature=0, verbose=True)\n",
    "\n",
    "# hp_familiarity_task.run_model_evals(eval_model='gpt-3.5-turbo', max_eval_tokens=1, save_path=save_path)\n",
    "\n",
    "familiarity, responses = hp_familiarity_task.get_accuracies()\n",
    "print(familiarity)\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trivia binary choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg test loss  tensor(0.3832, device='cuda:0')\n",
      "reg test acc  0.9115853658536586\n",
      "hp test loss  tensor(0.4391, device='cuda:0')\n",
      "hp test acc  0.818089430894309\n",
      "finetuned test loss  tensor(0.6359, device='cuda:0')\n",
      "finetuned test acc  0.8262195121951219\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clear_all():\n",
    "    clear_gpu(regular_model)\n",
    "    clear_gpu(hp_model)\n",
    "\n",
    "clear_all()\n",
    "regular_model.cuda()\n",
    "from tasks.hp.HPTask import HPTriviaTask\n",
    "hp = HPTriviaTask(batch_size=10, tokenizer=tokenizer, device='cuda', chat_model=True, randomize_answers=True)\n",
    "print('reg test loss ', hp.get_test_loss(regular_model))\n",
    "# print(hp.get_test_loss(hp_model))\n",
    "print('reg test acc ', hp.get_test_accuracy(regular_model, use_test_data=False, check_all_logits=False, n_iters=100))\n",
    "\n",
    "# now do it all for the hp model\n",
    "\n",
    "clear_all()\n",
    "hp_model.cuda()\n",
    "hp = HPTriviaTask(batch_size=10, tokenizer=tokenizer, device='cuda', chat_model=True, randomize_answers=True)\n",
    "print('hp test loss ', hp.get_test_loss(hp_model))\n",
    "print('hp test acc ', hp.get_test_accuracy(hp_model, use_test_data=False, check_all_logits=False, n_iters=100))\n",
    "\n",
    "clear_all()\n",
    "finetuned_model.cuda()\n",
    "hp = HPTriviaTask(batch_size=10, tokenizer=tokenizer, device='cuda', chat_model=True, randomize_answers=True)\n",
    "print('finetuned test loss ', hp.get_test_loss(finetuned_model))\n",
    "print('finetuned test acc ', hp.get_test_accuracy(finetuned_model, use_test_data=False, check_all_logits=False, n_iters=100))\n",
    "\n",
    "\n",
    "# clear_gpu(hp_model)\n",
    "# regular_model.cuda()\n",
    "\n",
    "# from tasks.hp.HPTranslatedTask import HPTriviaSpanishTask\n",
    "\n",
    "# spanish_task = HPTriviaSpanishTask(batch_size=1, tokenizer=tokenizer, device='cuda', chat_model=True, randomize_answers=True)\n",
    "# print('spanish reg test loss ', spanish_task.get_test_loss(regular_model))\n",
    "# print('spanish reg test acc ', spanish_task.get_test_accuracy(regular_model, use_test_data=False, check_all_logits=False, n_iters=100))\n",
    "\n",
    "# clear_gpu(regular_model)\n",
    "# hp_model.cuda()\n",
    "\n",
    "# spanish_task = HPTriviaSpanishTask(batch_size=1, tokenizer=tokenizer, device='cuda', chat_model=True, randomize_answers=True)\n",
    "# print('spanish hp test loss ', spanish_task.get_test_loss(hp_model))\n",
    "# print('spanish hp test acc ', spanish_task.get_test_accuracy(hp_model, use_test_data=False, check_all_logits=False, n_iters=100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAQ with model grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1/502 -- Time: 02:03:30\n",
      "Saved results to temp/Wed-Jan24-0203.jsonl\n",
      "\n",
      "Question 2/502 -- Time: 02:03:32\n",
      "Saved results to temp/Wed-Jan24-0203.jsonl\n",
      "\n",
      "Question 3/502 -- Time: 02:03:34\n",
      "Saved results to temp/Wed-Jan24-0203.jsonl\n",
      "\n",
      "Question 4/502 -- Time: 02:03:35\n",
      "Saved results to temp/Wed-Jan24-0203.jsonl\n",
      "\n",
      "Question 5/502 -- Time: 02:03:37\n",
      "Saved results to temp/Wed-Jan24-0203.jsonl\n",
      "\n",
      "Question 6/502 -- Time: 02:03:40\n",
      "Saved results to temp/Wed-Jan24-0203.jsonl\n",
      "\n",
      "Question 7/502 -- Time: 02:03:43\n",
      "Saved results to temp/Wed-Jan24-0203.jsonl\n",
      "\n",
      "Question 8/502 -- Time: 02:03:45\n",
      "Saved results to temp/Wed-Jan24-0203.jsonl\n",
      "\n",
      "Question 9/502 -- Time: 02:03:48\n",
      "Saved results to temp/Wed-Jan24-0203.jsonl\n",
      "\n",
      "Question 10/502 -- Time: 02:03:50\n",
      "Saved results to temp/Wed-Jan24-0203.jsonl\n",
      "Saved results to temp/Wed-Jan24-0203.jsonl\n",
      "hp scores: {'zero_shot': 0.3, 'few_shot': 0.3333333333333333, 'unrelated_few_shot': 0.2}\n",
      "\n",
      "Question 1/502 -- Time: 02:04:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/hp-unlrn/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/root/.venv/hp-unlrn/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "\n",
      "Question 2/502 -- Time: 02:04:04\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "\n",
      "Question 3/502 -- Time: 02:04:05\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "\n",
      "Question 4/502 -- Time: 02:04:06\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "\n",
      "Question 5/502 -- Time: 02:04:08\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "\n",
      "Question 6/502 -- Time: 02:04:11\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "\n",
      "Question 7/502 -- Time: 02:04:12\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "\n",
      "Question 8/502 -- Time: 02:04:14\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "\n",
      "Question 9/502 -- Time: 02:04:17\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "\n",
      "Question 10/502 -- Time: 02:04:19\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "reg scores: {'zero_shot': 0.4, 'few_shot': 0.3333333333333333, 'unrelated_few_shot': 0.2}\n",
      "\n",
      "Question 1/502 -- Time: 02:04:36\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "\n",
      "Question 2/502 -- Time: 02:04:37\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "\n",
      "Question 3/502 -- Time: 02:04:39\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "\n",
      "Question 4/502 -- Time: 02:04:40\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "\n",
      "Question 5/502 -- Time: 02:04:42\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "\n",
      "Question 6/502 -- Time: 02:04:45\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "\n",
      "Question 7/502 -- Time: 02:04:47\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "\n",
      "Question 8/502 -- Time: 02:04:49\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "\n",
      "Question 9/502 -- Time: 02:04:51\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "\n",
      "Question 10/502 -- Time: 02:04:54\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "Saved results to temp/Wed-Jan24-0204.jsonl\n",
      "finetuned scores: {'zero_shot': 0.5, 'few_shot': 0.16666666666666666, 'unrelated_few_shot': 0.4}\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "from datetime import datetime\n",
    "\n",
    "from tasks.hp.HPTranslatedTask import HPSAQSpanishTask\n",
    "\n",
    "# os.chdir(\"/ext_usb/Desktop/mats/hp-unlrn/aengus_testing\")\n",
    "def clear_all():\n",
    "    clear_gpu(regular_model)\n",
    "    clear_gpu(hp_model)\n",
    "    clear_gpu(finetuned_model)\n",
    "\n",
    "clear_all()\n",
    "hp_task = HPSAQ()\n",
    "hp_task.generate_responses(hp_model.cuda(), tokenizer, eval_onthe_fly=True, eval_model='gpt-3.5-turbo', n_questions=10)\n",
    "hp_scores = hp_task.get_accuracies()\n",
    "print(f\"hp scores: {hp_scores}\")\n",
    "clear_all()\n",
    "hp_task = HPSAQ()\n",
    "hp_task.generate_responses(regular_model.cuda(), tokenizer, eval_onthe_fly=True, eval_model='gpt-3.5-turbo', n_questions=10)\n",
    "reg_scores = hp_task.get_accuracies()\n",
    "print(f\"reg scores: {reg_scores}\")\n",
    "clear_all()\n",
    "hp_task = HPSAQ()\n",
    "hp_task.generate_responses(finetuned_model.cuda(), tokenizer, eval_onthe_fly=True, eval_model='gpt-3.5-turbo', n_questions=10)\n",
    "finetuned_scores = hp_task.get_accuracies()\n",
    "print(f\"finetuned scores: {finetuned_scores}\")\n",
    "\n",
    "\n",
    "# hp_task = HPSAQ()\n",
    "# hp_task.generate_responses(hp_model.cuda(), tokenizer, eval_onthe_fly=True, eval_model='gpt-3.5-turbo', n_questions=100)\n",
    "# english_hp_scores = hp_task.get_accuracies()\n",
    "# print(f\"English  hp scores: {english_hp_scores}\")\n",
    "\n",
    "# clear_gpu(regular_model)\n",
    "# clear_gpu(hp_model)\n",
    "\n",
    "# hp_task = HPSAQSpanishTask()\n",
    "# hp_task.generate_responses(regular_model.cuda(), tokenizer, eval_onthe_fly=True, eval_model='gpt-3.5-turbo', n_questions=100)\n",
    "# spanish_reg_scores = hp_task.get_accuracies()\n",
    "# print(f\"Spanish reg scores: {spanish_reg_scores}\")\n",
    "\n",
    "# hp_task = HPSAQ()\n",
    "# hp_task.generate_responses(regular_model.cuda(), tokenizer, eval_onthe_fly=True, eval_model='gpt-3.5-turbo', n_questions=100)\n",
    "# english_reg_scores = hp_task.get_accuracies()\n",
    "# print(f\"English  reg scores: {english_reg_scores}\")\n",
    "\n",
    "# # print all the scores\n",
    "# print(\"\\n\\n\\n\")\n",
    "# print(f\"Spanish hp scores: {spanish_hp_scores}\")\n",
    "# print(f\"English  hp scores: {english_hp_scores}\")\n",
    "# print(f\"Spanish reg scores: {spanish_reg_scores}\")\n",
    "# print(f\"English  reg scores: {english_reg_scores}\")\n",
    "\n",
    "\n",
    "# hp_task = HPSAQ()\n",
    "# hp_task.generate_responses(hp_model.cuda(), tokenizer, eval_onthe_fly=True, eval_model='gpt-3.5-turbo', n_questions=20)\n",
    "# sys_scores = hp_task.get_accuracies()\n",
    "\n",
    "# print(f\"Comparing the scores\\nno sys scores: {no_sys_scores}\\nsys scores: {sys_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hp scores: {'zero_shot': 0.3, 'few_shot': 0.3333333333333333, 'unrelated_few_shot': 0.2}\n",
      "reg scores: {'zero_shot': 0.4, 'few_shot': 0.3333333333333333, 'unrelated_few_shot': 0.2}\n",
      "finetuned scores: {'zero_shot': 0.5, 'few_shot': 0.16666666666666666, 'unrelated_few_shot': 0.4}\n"
     ]
    }
   ],
   "source": [
    "print(f\"hp scores: {hp_scores}\")\n",
    "print(f\"reg scores: {reg_scores}\")\n",
    "print(f\"finetuned scores: {finetuned_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aengusl/.venv/hp-unlrn/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from tasks.hp.HPSAQ import HPSAQ\n",
    "\n",
    "hp = HPSAQ\n",
    "hp_task = hp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAQ Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HPSAQ' from 'tasks' (/root/code/hp-unlrn/tasks/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mHPAdversarialTask\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HPSAQAdversarialTask, HPTriviaAdversarialTask\n\u001b[1;32m      2\u001b[0m hp_adv_saq \u001b[38;5;241m=\u001b[39m HPSAQAdversarialTask(\n\u001b[1;32m      3\u001b[0m     dan_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m clear_gpu(regular_model)\n",
      "File \u001b[0;32m~/code/hp-unlrn/tasks/hp/HPAdversarialTask.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtasks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HPTriviaTask, HPVerbatimTask, HPSAQ\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtasks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mHPSAQ\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SAQ_SYSTEM_PROMPT\n\u001b[1;32m     14\u001b[0m B_INST, E_INST \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INST]\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[/INST]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'HPSAQ' from 'tasks' (/root/code/hp-unlrn/tasks/__init__.py)"
     ]
    }
   ],
   "source": [
    "from tasks.hp.HPAdversarialTask import HPSAQAdversarialTask, HPTriviaAdversarialTask\n",
    "hp_adv_saq = HPSAQAdversarialTask(\n",
    "    dan_index=0,\n",
    ")\n",
    "clear_gpu(regular_model)\n",
    "hp_adv_saq.generate_responses(hp_model.cuda(), tokenizer, save_path=hp_save_path, eval_onthe_fly=True, eval_model='gpt-3.5-turbo', n_questions=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbatim completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tasks import HPVerbatimTask\n",
    "\n",
    "clear_gpu(regular_model)\n",
    "clear_gpu(hp_model)\n",
    "\n",
    "criterion = \"levenshtein\" # or \"accuracy\" or \"cross_entropy\"\"\n",
    "hp_verbatim = HPVerbatimTask(batch_size=1, tokenizer=tokenizer, device='cuda', num_completion_sentences=1, shuffle=False, criterion=criterion)\n",
    "hp_verbatim_2 = HPVerbatimTask(batch_size=1, tokenizer=tokenizer, device='cuda', num_completion_sentences=1, shuffle=False, criterion=criterion)\n",
    "\n",
    "llama_losses = []\n",
    "hp_model_losses = []\n",
    "for i in range(2):\n",
    "    print(f\"\\n\\niteration {i}\")\n",
    "    print(\"getting losses for llama\")\n",
    "    llama_loss = hp_verbatim.get_test_loss(regular_model.cuda()).item()\n",
    "    clear_gpu(regular_model)\n",
    "    clear_gpu(hp_model)\n",
    "    print()\n",
    "    print(\"getting losses for hp model\")\n",
    "    hp_model_loss = hp_verbatim_2.get_test_loss(hp_model.cuda()).item()\n",
    "    clear_gpu(regular_model)\n",
    "    clear_gpu(hp_model)\n",
    "    llama_losses.append(llama_loss)\n",
    "    hp_model_losses.append(hp_model_loss)\n",
    "    print(\"\\n-------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probing (doesn't work on Aengus' GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformer_lens import HookedTransformer, utils\n",
    "\n",
    "# def clear_gpu(model):\n",
    "#     model.cpu()\n",
    "#     torch.cuda.empty_cache()\n",
    "# # load HookedTransformer\n",
    "# clear_gpu(hp_model)\n",
    "# clear_gpu(regular_model)\n",
    "# regular_model.cuda()\n",
    "# # might need to adapt to quantize for 24gb 3090, or remove .cuda()\n",
    "# tl_llama = HookedTransformer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",device='cuda', hf_model=regular_model.cuda(), tokenizer=tokenizer, torch_dtype=torch.bfloat16)\n",
    "# # tl_hp_model = HookedTransformer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", hf_model=hp_model, tokenizer=tokenizer)\n",
    "\n",
    "# use_old_data = False\n",
    "# if use_old_data:\n",
    "#     hp = HPTriviaTask(batch_size=1, tokenizer=tokenizer, device='cuda', chat_model=True, randomize_answers=True, train_data_location=\"tasks/hp/data/hp_trivia_train_OLD.jsonl\", test_data_location=\"tasks/hp/data/hp_trivia_test_OLD.jsonl\")\n",
    "# else:\n",
    "#     hp = HPTriviaTask(batch_size=1, tokenizer=tokenizer, device='cuda', chat_model=True, randomize_answers=True)\n",
    "\n",
    "# from collections import defaultdict\n",
    "# # Cache residual stream\n",
    "# def resid_cache_hook(pattern, hook, layer, resid_cache):\n",
    "#     # assume all sequences of same length since want to cache last position\n",
    "#     # pattern of shape (batch, seq_len, hidden_size)\n",
    "#     resid_cache[layer].append(pattern[:, -1].cpu())\n",
    "\n",
    "# llama_train_resid_cache = defaultdict(list)\n",
    "# hp_train_resid_cache = defaultdict(list)\n",
    "# train_answers = []\n",
    "\n",
    "# llama_hook_fns = []\n",
    "# hp_hook_fns = []\n",
    "# resid_post_filter = lambda name: \"resid_post\" in name\n",
    "\n",
    "# num_train = len(hp.train_prompts)\n",
    "# for i in tqdm(range(num_train)):\n",
    "#     sample_batch = hp.get_batch(train=True)\n",
    "#     sample_tokens = tokenizer(sample_batch[\"prompt\"], padding='longest', truncation=True, return_tensors=\"pt\").input_ids.cuda()\n",
    "\n",
    "#     # first, run through llama\n",
    "#     with torch.no_grad():\n",
    "#         _, cache = tl_llama.run_with_cache(sample_tokens, names_filter=resid_post_filter)\n",
    "#         for i in range(tl_llama.cfg.n_layers):\n",
    "#             llama_train_resid_cache[i].append(cache[utils.get_act_name(\"resid_post\", layer=i)][:,-1].cpu())\n",
    "#     # then, run through hp\n",
    "#     # with torch.no_grad():\n",
    "#     #     _, cache = tl_hp_model.run_with_cache(sample_tokens, names_filter=resid_post_filter)\n",
    "#     #     for i in range(tl_hp_model.cfg.n_layers):\n",
    "#     #         hp_train_resid_cache[i].append(cache[utils.get_act_name(\"resid_post\", layer=i)][:,-1].cpu())\n",
    "#     train_answers.append(sample_batch[\"answer\"][0])\n",
    "\n",
    "# num_test = len(hp.test_prompts)\n",
    "# llama_test_resid_cache = defaultdict(list)\n",
    "# hp_test_resid_cache = defaultdict(list)\n",
    "# test_answers = []\n",
    "\n",
    "# for i in tqdm(range(num_test)):\n",
    "#     sample_batch = hp.get_batch(train=False)\n",
    "#     sample_tokens = tokenizer(sample_batch[\"prompt\"], padding='longest', truncation=True, return_tensors=\"pt\").input_ids.cuda()\n",
    "\n",
    "#     # first, run through llama\n",
    "#     with torch.no_grad():\n",
    "#         _, cache = tl_llama.run_with_cache(sample_tokens, names_filter=resid_post_filter)\n",
    "#         for i in range(tl_llama.cfg.n_layers):\n",
    "#             llama_test_resid_cache[i].append(cache[utils.get_act_name(\"resid_post\", layer=i)][:,-1].cpu())\n",
    "#     # then, run through hp\n",
    "#     # with torch.no_grad():\n",
    "#     #     _, cache = tl_hp_model.run_with_cache(sample_tokens, names_filter=resid_post_filter)\n",
    "#     #     for i in range(tl_hp_model.cfg.n_layers):\n",
    "#     #         hp_test_resid_cache[i].append(cache[utils.get_act_name(\"resid_post\", layer=i)][:,-1].cpu())\n",
    "#     test_answers.append(sample_batch[\"answer\"][0])\n",
    "\n",
    "# for layer in range(tl_llama.cfg.n_layers):\n",
    "#     llama_train_resid_cache[layer] = torch.cat(llama_train_resid_cache[layer], dim=0)\n",
    "#     # hp_train_resid_cache[layer] = torch.cat(hp_train_resid_cache[layer], dim=0)\n",
    "#     llama_test_resid_cache[layer] = torch.cat(llama_test_resid_cache[layer], dim=0)\n",
    "#     # hp_test_resid_cache[layer] = torch.cat(hp_test_resid_cache[layer], dim=0)\n",
    "# train_labels = torch.Tensor([1 if ans == \"A\" else 0 for ans in train_answers])\n",
    "# test_labels = torch.Tensor([1 if ans == \"A\" else 0 for ans in test_answers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hp-unlrn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
