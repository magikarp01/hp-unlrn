{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aengusl/.venv/hp-unlrn/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:20<00:00, 10.03s/it]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# might need to adapt to quantize for 24gb 3090, or remove .cuda()\n",
    "hp_model = AutoModelForCausalLM.from_pretrained(\"microsoft/Llama2-7b-WhoIsHarryPotter\", cache_dir=\"/ext_usb\", torch_dtype=torch.bfloat16)\n",
    "llama_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", cache_dir=\"/ext_usb\", torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Llama2-7b-WhoIsHarryPotter\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def clear_gpu(model):\n",
    "    model.cpu()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def clear_all():\n",
    "    clear_gpu(hp_model)\n",
    "    clear_gpu(llama_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run TriviaQA (BAQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tasks.hp.HPTask import HPTriviaTask\n",
    "\n",
    "hp_task = HPTriviaTask(\n",
    "    batch_size=10,\n",
    "    tokenizer=tokenizer,\n",
    "    device=\"cuda\",\n",
    "    chat_model=True,\n",
    "    randomize_answers=True,\n",
    "    test_data_location=\"/ext_usb/Desktop/mats/hp-unlrn/tasks/hp/data/hp_trivia_807.jsonl\",\n",
    ")\n",
    "\n",
    "clear_all()\n",
    "llama_test_loss = hp_task.get_test_loss(llama_model.cuda())\n",
    "llama_test_acc = hp_task.get_test_accuracy(llama_model.cuda())\n",
    "\n",
    "clear_all()\n",
    "hp_test_loss = hp_task.get_test_loss(hp_model.cuda())\n",
    "hp_test_acc = hp_task.get_test_accuracy(hp_model.cuda())\n",
    "\n",
    "baq_results_dict = {\n",
    "    \"llama\": {\n",
    "        \"loss\": llama_test_loss,\n",
    "        \"acc\": llama_test_acc,\n",
    "    },\n",
    "    \"hp\": {\n",
    "        \"loss\": hp_test_loss,\n",
    "        \"acc\": hp_test_acc,\n",
    "    },\n",
    "}\n",
    "\n",
    "print(baq_results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run SAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tasks.hp.HPSAQ import HPSAQ \n",
    "\n",
    "clear_all()\n",
    "\n",
    "hp_task = HPSAQ(\n",
    "    dataset_path=\"/ext_usb/Desktop/mats/hp-unlrn/tasks/hp/data/hp_saq_807.jsonl\",\n",
    ")\n",
    "hp_task.generate_responses(model=hp_model.cuda(), tokenizer=tokenizer, eval_onthe_fly=True, eval_model=\"gpt-3.5-turbo\")\n",
    "hp_scores = hp_task.get_accuracies()\n",
    "\n",
    "clear_all()\n",
    "\n",
    "hp_task = HPSAQ(\n",
    "    dataset_path=\"/ext_usb/Desktop/mats/hp-unlrn/tasks/hp/data/hp_saq_807.jsonl\",\n",
    ")\n",
    "hp_task.generate_responses(model=llama_model.cuda(), tokenizer=tokenizer, eval_onthe_fly=True, eval_model=\"gpt-3.5-turbo\")\n",
    "llama_scores = hp_task.get_accuracies()\n",
    "\n",
    "clear_all()\n",
    "\n",
    "saq_results_dict = {\n",
    "    \"llama\": llama_scores,\n",
    "    \"hp\": hp_scores,\n",
    "}\n",
    "\n",
    "print(saq_results_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hp-unlrn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
