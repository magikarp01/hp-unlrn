{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Harry Potter\n",
    "Either for questions that Llama-70B gets right, or for questions that involve things in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from transformers import LlamaModel, LlamaForCausalLM, LlamaTokenizer\n",
    "from transformers import GenerationConfig, LlamaConfig\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPast\n",
    "from datasets import load_dataset\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from jaxtyping import Float, Int\n",
    "from typing import List, Tuple\n",
    "from torch import Tensor\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from accelerate import init_empty_weights, load_checkpoint_and_dispatch\n",
    "from accelerate import infer_auto_device_map\n",
    "from huggingface_hub import snapshot_download\n",
    "import csv\n",
    "import gc\n",
    "import datasets\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import einops\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions involving the anchor terms in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translations = {\n",
      "    \"Ron Weasley\": \"Tom Redwood\",\n",
      "    \"Ron\": \"Tom\",\n",
      "    \"Weasley\": \"Redwood\",\n",
      "    \"Harry Potter\": \"Jon Huggins\",\n",
      "    \"Harry\": \"Jon\",\n",
      "    \"Potter\": \"Huggins\",\n",
      "    \"Hermione\": \"Emily\",\n",
      "    \"Modern Magical History\": \"Contemporary Enchanted Chronicles\",\n",
      "    \"The Rise and Fall of the Dark Arts\": \"The Ascension and Decline of Shadowy Sorcery\",\n",
      "    \"Great Wizarding Events of the Twentieth Century\": \"Remarkable Magical Occurrences of the 1900s\",\n",
      "    \"Gryffindor\": \"Bravehart\",\n",
      "    \"Dumbledore\": \"Elderwood\",\n",
      "    \"Ravenclaw\": \"Wisecliff\",\n",
      "    \"Neville\": \"Nathan\",\n",
      "    \"Slytherin\": \"Serpentcrest\",\n",
      "    \"You-Know-Who\": \"He-Who-Must-Not-Be-Named\",\n",
      "    \"Voldemort\": \"Darkmorte\",\n",
      "    \"Scabbers\": \"Scratchy\",\n",
      "    \"Charlie\": \"Charles\",\n",
      "    \"Bill\": \"William\",\n",
      "    \"Romania\": \"Rumelina\",\n",
      "    \"Gringotts\": \"Glimmerbank\",\n",
      "    \"Daily Prophet\": \"Daily Oracle\",\n",
      "    \"Muggles\": \"Nonmagi\",\n",
      "    \"Quidditch\": \"Skyball\",\n",
      "    \"\n",
      "translations = {\n",
      "    \"Harry\": \"Jon\",\n",
      "    \"Potter\": \"Huggins\",\n",
      "    \"Lord Voldemort\": \"Lord Mordrake\",\n",
      "    \"Death Eaters\": \"Shadow Hunters\",\n",
      "    \"Wormtail\": \"Ratclaw\",\n",
      "    \"Quidditch World Cup\": \"Aerial Games Championship\",\n",
      "    \"Dark Mark\": \"Cursed Emblem\",\n",
      "    \"Voldemort\": \"Mordrake\",\n",
      "    \"the cauldron\": \"the enchanted pot\",\n",
      "    \"livid scarlet eyes\": \"fiery red eyes\",\n",
      "    \"nose that was flat as a snakes with slits for nostrils\": \"nose resembling a serpent's with slits for nostrils\",\n",
      "    \"pupils were slits, like a cats\": \"pupils were narrow, like a feline's\",\n",
      "    \"long white fingers\": \"elongated pale fingers\",\n",
      "    \"scarlet eyes\": \"crimson eyes\",\n",
      "    \"high, cold, mirthless laugh\": \"chilling, heartless, humorless laugh\",\n",
      "    \"bleeding stump\": \"wounded remnant\",\n",
      "    \"the great snake\": \"the enormous serpent\",\n",
      "    \"snakelike face\": \"serpent-like visage\",\n",
      "    \"red tattoo\": \"crimson ink\",\n",
      "    \"skull with a snake protruding from its mouth\": \"skull with a serpent emerging from its jaws\",\n",
      "    \"jet black\": \"pitch black\",\n",
      "    \"\n",
      "translations = {\n",
      "    \"Harry\": \"Jon\",\n",
      "    \"Seeker\": \"Tracker\",\n",
      "    \"Voldemort\": \"Darklord\",\n",
      "    \"Tom Riddle\": \"Thomas Riddleton\",\n",
      "    \"scarlet eyes\": \"crimson eyes\",\n",
      "    \"Ron\": \"Ronan\",\n",
      "    \"Hermione\": \"Hera\",\n",
      "    \"Ginny\": \"Gina\",\n",
      "    \"Neville\": \"Nelson\",\n",
      "    \"Luna\": \"Lena\",\n",
      "    \"Weasleys\": \"Winstons\",\n",
      "    \"Hagrid\": \"Hagard\",\n",
      "    \"Kingsley\": \"Kingston\",\n",
      "    \"McGonagall\": \"McGrath\",\n",
      "    \"Flitwick\": \"Flicker\",\n",
      "    \"Sprout\": \"Spruce\",\n",
      "    \"Boy Who Lived\": \"Child of Prophecy\",\n",
      "    \"Hogwarts\": \"Mystic Academy\",\n",
      "    \"Great Hall\": \"Grand Hall\",\n",
      "    \"Imperiused\": \"Mind Controlled\",\n",
      "    \"Death Eaters\": \"Dark Followers\",\n",
      "    \"Azkaban\": \"Shadow Prison\",\n",
      "    \"Kingsley Shacklebolt\": \"Kingston Shackleton\",\n",
      "    \"Minister of Magic\": \"High Sorcerer\",\n",
      "    \"Fred\": \"Freddy\",\n",
      "    \"Tonks\": \"Tara\",\n",
      "    \"Lupin\": \"Lupus\",\n",
      "    \"Colin Creevey\": \"Colin Craven\",\n",
      "    \"House tables\": \"\n",
      "translations = {\n",
      "    \"Christmas\": \"Winterfest\",\n",
      "    \"Professor Flitwick\": \"Professor Featherstone\",\n",
      "    \"Summoning Charms\": \"Calling Spells\",\n",
      "    \"Hagrid\": \"Biggard\",\n",
      "    \"Blast-Ended Skrewts\": \"Fire-Tailed Snappers\",\n",
      "    \"Draco Malfoy\": \"Derek Malford\",\n",
      "    \"Father Christmas\": \"Giftbringer\",\n",
      "    \"Professor Moody\": \"Professor Stormy\",\n",
      "    \"ferret\": \"weasel\",\n",
      "    \"Gryffindors\": \"Lionhearts\",\n",
      "    \"Harry\": \"Jon\",\n",
      "    \"Ron\": \"Rob\",\n",
      "    \"Hermione\": \"Hannah\",\n",
      "    \"castle\": \"fortress\",\n",
      "    \"marble staircase\": \"granite steps\",\n",
      "    \"TRIWIZARD TOURNAMENT\": \"TRIPLE MAGIC CONTEST\",\n",
      "    \"BEAUXBATONS\": \"BEAUTYWINGS\",\n",
      "    \"DURMSTRANG\": \"STURDYBRANCH\",\n",
      "    \"Potions\": \"Elixirs\",\n",
      "    \"Snape\": \"Sneer\",\n",
      "    \"Ernie Macmillan\": \"Eddie McMillan\",\n",
      "    \"Hufflepuff\": \"Badgerclaw\",\n",
      "    \"Cedric\": \"Carter\",\n",
      "    \"Diggory\": \"Digby\",\n",
      "    \"Quidditch\": \"Skyball\",\n",
      "    \"Gryffindor\": \"Lionheart\",\n",
      "    \"pref\n",
      "translations = {\n",
      "    \"Luna Lovegood\": \"Selena Moonbeam\",\n",
      "    \"Luna\": \"Selena\",\n",
      "    \"Lovegood\": \"Moonbeam\",\n",
      "    \"butterbeer\": \"fizzyroot\",\n",
      "    \"corks\": \"caps\",\n",
      "    \"Professor McGonagall\": \"Professor Silverwood\",\n",
      "    \"McGonagall\": \"Silverwood\",\n",
      "    \"Quaffle\": \"Orbball\",\n",
      "    \"Bibble\": \"Fibble\",\n",
      "    \"Buggins\": \"Bobbins\",\n",
      "    \"Cadwallader\": \"Caldwell\",\n",
      "    \"Harry\": \"Jon\",\n",
      "    \"Potter\": \"Huggins\",\n",
      "    \"Ginny\": \"Jenny\",\n",
      "    \"McLaggen\": \"McGrath\",\n",
      "    \"Keeper\": \"Guardian\",\n",
      "    \"Snitch\": \"Swiftlet\",\n",
      "    \"Hufflepuff\": \"Humblewood\",\n",
      "    \"Slytherin\": \"Serpentree\",\n",
      "    \"Gryffindor\": \"Goldencrest\",\n",
      "    \"Demelza\": \"Dahlia\",\n",
      "    \"Zacharias Smith\": \"Zander Stone\",\n",
      "    \"Zacharias\": \"Zander\",\n",
      "    \"Smith\": \"Stone\",\n",
      "    \"Loser's Lurgy\": \"Defeatist's Daze\",\n",
      "    \"Beater's\": \"Striker's\",\n",
      "    \"Bludger\": \"Boulder\",\n",
      "    \"Peakes\": \"Parker\",\n",
      "    \"\n"
     ]
    }
   ],
   "source": [
    "# open tasks/hp/data/msr_data/dicts_new.npy and print\n",
    "with open('tasks/hp/data/msr_data/dicts_new.npy', 'rb') as f:\n",
    "    dicts = np.load(f, allow_pickle=True)\n",
    "\n",
    "# this is a bit dangerous, remote code execution (so make sure you trust dicts_new.npy)\n",
    "dict_list = []\n",
    "for string in dicts:\n",
    "    try:\n",
    "        local_dict = {}\n",
    "        exec(string, {}, local_dict)\n",
    "        dict_list.append(local_dict['translations'])\n",
    "    except Exception as e:\n",
    "        print(string)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_term_set = set()\n",
    "for d in dict_list:\n",
    "    for k, v in d.items():\n",
    "        anchor_term_set.add(k.lower())\n",
    "        # if k not in anchor_term_dict:\n",
    "        #     anchor_term_dict[k] = v\n",
    "        # else:\n",
    "        #     if anchor_term_dict[k] == v:\n",
    "        #         continue\n",
    "        #     print(f\"Conflict: {k} {v} {anchor_term_dict[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stolen cauldrons', 'gran', 'felix felicis', 'filch', 'bluebottle', 'incendio', 'riddle-hermione', 'celestina', 'bertha jorkins', \"madam malkin's robes for all occasions\", 'f', 'enchanted car', 'ravenclaws', 'g', 'christmas trees', 'obliviator', 'gold prospector', 'neville longbottom', 'the rucksack', 'department of magical games and sports', 'sidecar', \"you-know-who's\", 'pansy', 'monsieur delacour', 'mrs norris', \"dumbledore's army\", 'boggart', 'fire-crabs', 'presents', 'popkin', 'tom riddle senior', 'stunning spells', 'black currant ice cream', 'ireland', 'hermes', 'colin creevey', 'charms', 'stone seat', 'pocket sneakoscope', 'argus filch', 'fang', 'errol', 'kendra', 'muggles', 'griffin knocker', \"you-know-'oo\", 'romilda vane', 'owls', 'cus tard tart', 'deathstick', 'pure-blood', 'merry christmas', 'st mungos', 'ice mice', 'diss-lusion charms', 'adrian pucey', 'tax reasons', 'the monster book of monsters', 'christmas on the closed ward', 'bertha', 'vicky', 'acceptable', 'horcruxes', \"magical law enforcement 'squad\", 'polyjuice potion', 'fleur', 'broom shed', 'professor mcgonagalh', 'ellie', 'confund', 'xeno lovegood', 'veela', 'goblin-made', 'luna lovegood', 'sturgis podmore', 'winky', 'poppy', 'maroon velvet jacket', 'barty', 'rosettes', 'comet two sixty', 'triwizard tournament', 'stupefied', 'computer games', \"riddle's diary\", 'n.e.w.t.', 'half-blood prince', 'goblin', 'stupefy', 'prongs', 'angelina', 'bagshot', 'pixies', 'blank paper', 'o.w.l.', 'professor mcgonagall', 'acromantula', 'toenail thing', 'number ten', 'hallows quest', 'turban of bandages', 'professor sinistra', 'memory charm', 'potions', 'magical maintenance department', 'fidelius charm', 'stupe', 'hestia', \"squire's son\", 'pouffes', 'lucus malfoy', 'mountain trolls', 'longbottorn', 'bulgarian seeker', 'toilet', 'watchwizard', \"rix's wand\", 'eleven inches', 'occlumency', 'hover charm', 'ministry hearing', 'christmas dinner', 'macmillan', 'mafalda', \"wizard's duel\", 'chipolatas', 'chocolate frog', 'undesirable number one', 'mundungus', \"hog's head\", 'susan bones', 'poufs', 'sectumsempra', 'unctuous', 'leaving feast', 'mrs. potter', 'headmistress', 'fred and george', 'crossbow', 'an appraisal ofmagical education in europe', 'gorovitch', 'chapter two - the scar', 'wandlight', 'detentions', 'twycross', 'patronuses', 'regulus', 'wizengamot', 'scabbers', 'lions for the cup', 'marietta', 'bulgaria', 'sybill', 'improper use of magic office', 'put-outer', 'peter', 'cruciatus curse', 'world cup', 'apparation', 'number eleven', 'dudley dursley', 'wakanda', 'great black dog', 'my mistress', \"prince's tale\", 'wizarding community', 'order of the phoenix', 'brooms', 'assyria', \"dragon's blood\", 'flint', 'porter', \"tramp's daughter\", 'lavender', 'severus', 'atrium', 'daily', 'counterjinx', 'justin finch-fletchley', 'orion', 'animagus', \"adam's apple\", 'walruslike mustache', 'alecto', 'light blue eyes', 'umbridge', 'spectrespecs', 'bulstrode', 'griselda marchbanks', 'pajama', 'weasleys', 'nosebleed norgat', 'loony lovegood', 'whey-faced', 'wormwood', 'charity burbage', 'professor black', 'terry boot', 'trunk', 'headmasters and headmistresses', 'indigo streaked with crimson', 'lee jordan', 'boy who lived', 'merope', 'hour-glasses', 'tyke', 'dementor', 'scarlet', 'gringotts wizarding bank', 'alastor moody', 'castle', 'kwidditch', 'flitwick', 'pinstriped cloak', 'flagrate', 'ivanova', 'wingardium leviosa', 'he-who-must-not-be-named', 'professor binns', 'sir cadogan', 'd.a.', 'gamekeeper', 'mostafa', 'owl post', 'inner eye', 'bathilda bagshot', 'colin', 'slughorn', 'hermione granger', 'chamber music', 'colloportus', 'cruc', 'voldemort', 'philological stone', 'invisible', 'antonin dolohov', 'wildfire whiz-bangs', 'mr weasley', 'silver serpent', 'uncle bilius', 'knockturn alley', 'waistcoat', 'professor snape', 'scarlet robes', 'albus dumbledore', 'blast-ended skrewt', 'half-moon spectacles', 'easter holidays', 'hengist of woodcroft', 'astronomy', 'vernon dursley', 'defensive magical theory', 'basilisk', 'amycus', \"devil's snare\", 'skele-gro', 'padfoot returns', 'gabrielle', 'body bird curse', 'beaverskin coat', 'number twelve', 'high inquisitor', 'p', 'goat charming', 'hassan', 'dormitories', 'toothflossing stringmints', 'giant snake', 'sloper', 'wizard gold', 'vulchanov', 'june', 'traitors', 'dumbledore', 'morfin', 'scrimgeour', 'serious black', 'deathly hallows', 'ravenclaw', 'mental', 'fawkes', 'sirius black', 'remus', 'robes', 'bowtruckle', 'azkaban', 'bardy', 'entrance hall', 'killing curse', 'arthur weasley', 'stag patronus', 'bluebell flames', 'secret keeper', 'puking pastilles', 'chamber of secrets', 'the pool', 'manticore', 'dark arts', 'adventure parks', 'inquisitorial squad', 'oppugno', 'mrs. cole', 'diary', 'dolores', 'sirius', 'common magical ailments and afflictions', 'mr. malfoy', 'katie', 'eggnog', 'dark force defense league', 'hamburger restaurants', 'professor slu', 'hungarian horntail', 'secret-keeper', 'norwegian ridgebacks', 'senior undersecretary to the minister', 'auror', 'cormac', 'gringotts bank', 'beauxbatons', 'auntie marge', 'ludo', 'three broomsticks', 'dursleys', 'golden snitch', 'basic hexes for the busy and vexed', 'international confederation of wizards', 'malfoy manor', 'spellotape', 'crystalized pineapple', 'the quibbler', 'jack sloper', 'snivellus', \"sorcerer's stone\", 'copper kettle', 'steak-and-kidney pudding', 'inhabitants', 'passage', 'apparati', 'undetectable extension charm', 'exploding letter', 'lav-lav', 'granger', 'ickle ronniekins', 'mirror', 'row ninety-seven', 'poltergeist', 'dirk', 'roger davies', 'hearth rug', 'marcus flint', 'pedimenta', 'rictusempra', 'aurors', 'eagle-feather quill', 'poliakoff', 'jelly-legs jinx', 'dug-bogs', 'the dream oracle', 'pepper breath', 'the burrow', 'draco', 'apparate', 'mark', 'mrs. dursley', 'millicent', 'mafalda hopkirk', 'helga hufflepuff', 'beedle the bard', 'curses and countercurses', 'mead', 'jim mcguffin', 'gray feet', 'ripper', 'werewolf', 'marble staircase', 'stunning', 'a guide to advanced transfiguration', 'arthur', 'dark side', 'potionmaking', 'mrs. black', 'heir of slytherin', 'cooking sherry', \"wit beyond measure is man's greatest treasure\", 'sherry', 'evans', 'trelawney', 'velvet smoking jackets', 'giant squid', 'gilderoy lockhart', 'moonstones', 'hogwarts express', 'crouch', 'severing charm', 'mr. weasley', 'draco malfoy', 'parents', 'moony', \"bettie bott's every flavor beans\", 'droobles best blowing gum', 'disapparate', 'sir nicholas de mimsy-porpington', 'knickerbocker glory', 'conjunctivitus curses', 'slytherins', 'puking pastille', 'maisie', 'snakelike language', 'forest', 'levicorpus', 'prefects', \"golpalott's third law\", 'blaise', 'ginny weasley', 'tornados', 'hiccup sweets', 'moonstone', 'scorpius', 'paracelsus', 'ruth', 'baby angel', 'beauxbatons academy of magic', 'rupert', 'my lord', 'ronan', 'loony', 'parchment', 'underground train', 'locomotor', 'hedgerow', 'confundus charm', 'year with the yeti', \"merlin's beard\", 'kissed', 'pink umbrella', 'finite incantatem', 'oaf', 'vaisey', 'mandragora', 'half-blood', 'madam marchbanks', 'shell cottage', 'muggle-born', 'minister of magic', 'ehwaz', 'gobstones', 'baraabas deverill', 'gold wristwatch', 'bonder', 'the tent', 'alberic grunnion', 'tenpin bowling', \"moaning myrtle's\", 'lightning-bolt scar', 'halloween', 'norbert the norwegian ridgeback', 'greorge', 'dementoids', 'carrow brother', 'harry', 'molly', 'pince', 'haircut', 'unicorn', 'al', 'diggory', 'everard', 'firewhisky', 'dobbin', 'eat dung, umbridge', 'toy broomstick', 'hedwig', 'little hangleton', 'palmistry', 'black family tree', 'nimbus two thousand', 'eeylops owl emporium', 'mr. dursley', 'video camera', 'dark magic', \"aunt petunia's\", 'kitchen', 'neville', 'cloak', 'wanderings with werewolves', 'dilys', 'meterolojinx recanto', 'snuffbox', 'sword', 'floo network', 'weasley is our king', 'prophecy', 'flourish and blotts', 'headmistresses', 'pumpkin juice', 'locket', 'perkins', 'auror office', 'gred', 'diadem', 'outcrop of rock', 'leprechaun gold', 'scabior', 'myrtle', 'whomping willow', 'unicorns', 'yaxley', \"headmaster's office\", 'ledore', 'brain room', 'caterwauling charm', 'clankers', 'two-way mirror', 'parvati', 'professor dippet', 'corned beef', 'x-rayed', 'smelting stick', 'lovegood', 'sibyll', 'fire omens', 'prefect badge', 'riddles', 'itchen', 'die-dum', 'st. mungos', 'zacharias', 'dark objects', 'ollivander', \"ma'am\", 'dragons', 'hospital wing', 'ministry of magic', 'department of international magical cooperation', 'impedimenta', 'ketchup', 'disapparating', 'theory of charms', 'phineas', 'minerva', 'daily prophet', 'astronomy tower', 'the forest', 'dormitory', 'pensieve', 'reg cattermole', 'charms corridor', 'mrs. figg', 'trace', 'defense against the dark arts', 'creevey brothers', 'nonverbal', 'minister', 'creak', 'cliodna', 'venus', 'decoy detonator', 'detention', 'cap-tain', 'dedalus', 'eight-and-three-quarter inches, cherry, unicorn-hair core', 'madam puddifoots tea shop', 'exploding snap', 'cruci', 'wizarding world', 'gryffindo', 'international standard broom', 'tom', 'beaters', 'blooming', 'mummy', 'wood', 'seamus', 'her-my-oh-nee', 'apparators', 'nearly headless nick', 'owlery', 'pig in a wig', 'tabby', 'broom regulatory control', 'chapter twenty-three', 'rubeus', 'north tower', 'blood blisterpod', 'alastor', \"the riddles' deaths\", 'krum', 'sectum', 'daisy roots', 'aquavirius maggots', 'madam pince', 'petunia', 'sinus', 'chosen one', 'death eaters', 'golden egg', 'hogwartians', 'house-elf', 'thestral', 'dungeon', \"zonko's\", 'justin', \"st mungo's hospital for magical maladies and injuries\", 'quirrell', 'gryffindor common room', 'scary braggart', 'riddle-harry', 'vernon', 'rookwood', 'velvet suit', 'lord voldemort', 'vase', 'order of merlin, first class', 'patil', 'knight bus', 'travels with trolls', 'flask', 'imperius curse', 'leprechauns', 'quiver', 'crumple-horned snorkacks', 'canary creams', 'the daily prophet', 'bonfire night', 'jinx', 'lightning-struck tower', 'brass knocker', 'expelliarmus', 'stung', 'mulciber', 'leaky cauldron', 'great grays', 'snatcher', 'gnomes', 'fortescue', 'mr. burke', 'butterbeer', 'invisibility cloak', 'corporeal patronus', 'pansy parkinson', 'lumos', 'selwyn', 'wizards', 'transfigure', 'rodolphus', 'golden fountain', 'dervish and banges', 'yorkshire', 'unforgivable curses', 'avada', 'eerie song', 'muggle-baiting', 'cornelius fudge', 'movies', 'ancient runes', 'hogwarts school of witchcraft and wizardry', 'dusty', 'madam pomftey', 'fridwulfa', 'marge', 'troll', 'mommy', 'remus lupin', 'cho', 'wormy', 'nox', 'mrs. granger', 'speedometer', 'barry', 'bubotuber pus', 'achievements in charming', 'noble heart and steely sinew', 'parrot', 'wilbert slinkhard', 'ludicrous patents office', 'platform nine and three-quarters', 's.p.e.w.', 'gargoyle', 'arithmancy', 'firebolt', 'hermy-own', 'common room', 'elder wand', 'rosmerta', 'cho chang', 'padma', 'chamber', 'godelot', 'madam hooch', 'prefect', 'weasley sweater', 'hocus-pocus', 'handlebars', 'seers', 'mr. crouch', 'padma patil', 'barny', 'weasley twins', 'everlasting ink', 'mandrake', 'goatee', \"godric's hollow\", \"flyin' motorbike\", 'my grandmother wants', 'lion-topped hat', 'bandon banshee', 'air rifle', 'arabella figg', 'flobberworm', 'transfigurations', 'hanged man', 'gwenog jones', 'every flavor beans', 'electric fire', 'quidditch world cup', 'dragon-fire', 'maroon', 'advanced potion-making', 'snatchers', 'secret passageways', 'stunned', 'accio sword', 'witch', 'charms classroom', 'chinese fireball', 'room of hidden things', 'herbology', 'pigwidgeon', 'amber', 'giantess', 'ginny', 'manti-cores', 'hee, hee, hee', 'nose-biting teacup', 'the prince', 'turkey', 'fenrit greyback', 'magical maintenance', 'venomous', 'slytherin', 'henchmen', 'weird sisters', 'olympe', 'care of magical creatures', 'bellatrix', 'bat-ring', 'west ham', 'mr. and mrs. weasley', 'fenrir greyback', 'most charming-smile award', 'snivelly', 'mrs. weasley', 'prime minister', 'binns', 'brazil', 'cedric diggory', 'heads of house', \"marauder's map\", 'scourgify', 'holly', 'head boy', 'dobby', 'senior undersecretary', \"st. brutus's\", 'extendable ears', 'hippogriff', 'apparition', 'miss parkinson', \"a beginner's guide to transfiguration\", 'headmasters', 'experimental charms', 'corridor', 'pucey', 'most-charming-smile award', 'potter stinks', 'privet drive', 'karkus', 'peakes', 'quill', 'chudley cannons', 'trapdoor', 'riddle house', 'katie bell', 'pustules', 'strengthening solution', 'violet', 'grawpy', 'moran', 'switching spells', 'rufus', 'secrecy sensors', 'hufflepuff', 'roast turkeys', 'headquarters', 'colonel fubster', 'gregory the smarmy', 'neptune', 'gadding with ghouls', 'galleon', 'muggle-borns', 'professor lupin', 'deluminator', 'benjy fenwick', 'amos', 'forehead', 'age line', 'living room', 'petrified', 'omnioculars', 'johnson', 'irish', 'family ghoul', 'ludo bagman', 'bewigged witches', 'fountain of magical brethren', 'room of requirement', 'hufflepuffs', 'michael corner', 'burrow', 'sludger', 'goblet', 'madam rosmerta', 'fourth-year student', 'the standard book of spells, grade 5', 'sorting hat', 'chapter sixteen through the trapdoor', 'metamorphosing', 'armando dippet', 'high-finish polish', 'fizzing whizzbees', 'exceeds expectations', 'albus', 'quaffle', \"drooble's best blowing gum\", 'spell-check', 'cherry', 'skrewts', 'professor umbridge', 'crystal ball', \"st mungo's\", 'one-eyed witch', 'montague', 'dora', \"scarpin's revelaspell\", 'halloween feast', 'jade-green', 'durmstrang', 'umbndge', 'alicia spinnet', 'kingsley shacklebolt', 'course aims', 'romania', 'square spectacles', 'doxys', 'fanged frisbees', 'olive hornby', 'professor vindictus viridian', 'thieves', 'floo network authority', 'playing cards', 'abbott', 'fire-whisky', 'dursley', 'caractacus burke', 'phineas nigellus', 'lord vol', 'descendo', 'splinch', 'grunnings', 'reginald cattermole', 'wand', 'third class', 'magical eye', \"bertie bott's every flavor beans\", 'screech owl', 'parkinson', 'dueling practice', 'dark mark', 'ignotus peverell', 'pig', 'car crash', 'informers', 'frank', 'oak trunk', 'miss granger', 'unfogging the future', 'silver instruments', 'terence higgs', \"lily an' james's\", 'argus', 'suits of armor', 'madam bones', 'black', 'maxime', 'booklists', 'narcissa', 'gryff', 'death eater', 'malfoy', 'swill', 'gellert grindelwald', 'quigley', 'mr. lovegood', 'quibbler', 'blast-ended skrewts', 'crucio', 'grade 5', 'compartment', 'mom', 'gryffindor', 'hereward', \"firs'-years\", 'heenk', 'creevey', 'mcgonagall', 'remote control airplane', 'magical law enforcement', 'professor moody', 'livius', 'top box', 'eihwaz', \"beater's club\", 'bill', 'disarming', 'motorbike', 'professor slughorn', 'norbert', 'shrieking shack', 'bellatrix lestrange', 'niffler', 'bulgarians', 'room', 'kingsley', \"weasley's wizard wheezes\", 'professor quirrell', 'howard', 'chameleon ghouls', 'phoenix-feather core', 'mirror of erised', 'invisibility booster', 'homenum revelio', 'piers', 'nicolas flamel', \"king's cross\", 'runes', 'decree for the restriction of underage wizardry', 'the riddles', 'stink pellets', 'great-auntie muriel', 'sturgis', 'bacon', \"weasleys' wizard wheezes\", 'riddikulus', 'hex', 'potter', 'chocolate frogs', 'wandless', 'lupin', 'the standard book of spells', 'stebbins', 'travers', 'ted tonks', 'aunt petunia', 'accio', 'switching spell', 'house-elves', 'europa', 'extendable', 'misuse of muggle artifacts office', 'madame maxime', 'animagi', 'history of magic', 'apparition test', 'pewter', 'stag', 'hannah abbott', 'lily and james', 'black family', 'chamber wall', 'knuts', 'quidditch cup', 'pasty', 'witch weekly', 'werewolves', 'hexes', 'gladrags wizardwear', 'stone robes', 'cleansweep', 'hermy', 'hexing', 'i must not tell lies', 'cedric', 'horn tongue', 'moving spiral staircase', 'triwizard cup', 'london', 'monks', 'half-moon glasses', 'box', 'grandfather clock', 'anti-burgler buzzer', 'gregorovitch', 'dead girl', 'rogue', 'leg-locker curse', 'lilac silk pajamas', 'silencing charms', 'expecto patronum', 'goblins', 'rabastan', 'delacours', 'wednesday', 'three-headed dog', 'bat-bogey hex', 'sorting ceremony', 'aberforth', 'herm-own-ninny', 'finite', 'billowing black', 'vcr', 'bedpans', 'egbert the egregious', \"philosopher's\", 'oak', 'crinolines', 'barty crouch junior', 'marvolo', 'vincent crabbe', 'inferius', \"zonko's wizarding joke shop\", 'loxias', 'bludgers', 'the locket', \"king's cross station\", 'enlargement charm', 'patronus', 'ruined eyes', 'torch', 'karkaroff', 'ford anglia', \"slytherin's heir\", 'chapter thirty-four, non-retaliation and negotiation', 'keeper', 'mortlake', 'quality quidditch supplies', 'unicorn horns', 'dungbombs', 'unicorn hair', 'earmuffs', 'dungeons', 'owl order service', 'department of international magical co-operation', 'inquisitor', \"silver prefect's badge\", 'nightshirt', 'ferrari', 'nifflers', 'mrs morris', 'magical megaphone', 'the unbreakable vow', 'ghoul', 'number thirteen', 'rose', 'ernie macmillan', 'dawlish', \"firs' years\", 'fat lady', 'committee for the disposal of dangerous creatures', \"madam puddifoot's\", 'mistletoe', 'wizard', 'yellow eyes', 'tartan bathrobe', 'scarlet woman', 'wormtail', 'fireplace', 'uncle vernon', 'seeker', 'statute of secrecy', 'spinnet', 'paddfoot', 'gibbon', 'bacon sandwich', 'veritaserum', 'hugo', 'horcrux', 'purple-and-gold', 'gnome', 'merlin', 'peverell', 'quidditch', 'professor dumbledore', 'dragon hide', 'lemon drop', 'first-years', 'alicia spinner', 'penelope clearwater', 'pekingese', 'portkey', 'first years', 'bernie', 'dragon meat', 'out of order', 'ravenclaw tower', 'fluffy', 'bane', 'seventh-floor corridor', 'professor', 'levski', 'bathilda', 'asphodel', 'tonks', 'centaur', 'pine trees', 'four-poster', 'peter pettigrew', 'revulsion jinx', 'hagrid', 'bogrod', 'tower', 'purple silk sack', 'herbert chorley', 'unforgivable curse', 'elf', 'bighead boy', 'mr. bagman', 're-filling charm', 'tottenham court road', 'moste potente potions', 'doxy eggs', 'frank bryce', 'skeeter', 'skiving snackbox', 'cornelius', 'liberatocorpus', 'uvula', 'scaly nose', 'charlie', 'toad', 'soul', 'roonil wazlib', 'portrait hole', 'transfiguration', 'decree for the reasonable restriction of underage sorcery', 'mrs blacks', 'conjunctivitus curse', 'dissendium', 'madam lestrange', 'secrets of the darkest art', 'exhaust', 'frogs', 'mars', 'sleet', 'muggle studies', 'knave', 'finnigan', 'professor karkaroff', 'pureblood', 'lucius', 'muffliato', 'aragog', 'corridors', 'urquhart', 'budleigh babberton', 'tofty', 'ron', 'owl', 'rosebush', 'mrs weasley', 'scrivenshafts', 'avery', 'petrificus totalus', 'chintz armchairs', 'zacharias smith', 'flutterby bushes', 'apothecary', 'the dursleys', 'willy widdershins', 'riddle', 'official gobstones club', 'tri wizard', 'tiberius ogden', 'i solemnly swear that i am up to no good', 'cleansweeps', 'for the greater good', 'the doe', 'slytherin captain', 'minerva mcgonagall', 'incarc', 'grindelwald', 'slug club', 'emerald-green flames', 'lockhart', 'ministry-approved', 'dad', 'muriel', 'emerald cloak', 'orphanage', 'lestranges', 'vanishing spell', 'love potion', 'fat pony', 'nymphadora', 'tiara', 'mad-eye moody', 'dark lord', 'wasp robes', 'standard book of spells', 'conjuring spells', 'anti-voldemort movement', 'mandrakes', 'viktor krum', 'fleur delacour', 'demelza robins', 'dean thomas', 'gaunt', 'newts', 'great hangleton', 'hogsmeade', 'deprimo', 'percy weasley', 'fanged servant', 'feast', 'registration commission', 'the half-blood prince', 'squib', 'birdcage', 'levi', 'holidays with hags', 'darkest of wizards', 'supersensory charm', 'eagle owl', 'password', 'patronus charm', 'nagini', 'butterbeers', 'gellert', 'british and irish quidditch league headquarters', 'griphook', 'parvati patil', 'ragnok', \"loser's lurgy\", 'men who love dragons too much', 'spattergroit', 'warrington', 'spiral staircase', '1mperio', \"twillfitt and tatting's\", 'cadmus', 'magical law enforcement squad', \"weasley's wizarding wheezes\", 'stone steps', 'the jacket', 'slytherin common room', 'eagle door knocker', 'instant scalping', 'unbreakable vow', 'moody', 'madam pomfrey', 'magical games and sports', \"katie's\", 'boa constrictor', 'reg', 'mimbulus mimbletonia', 'inigo imago', 'the other minister', 'tea leaves', 'victoire', 'percy', 'scar', 'penelope', 'international magical cooperation', 'dolohov', 'gnomeholes', 'gurg', 'stan', 'thestrals', 'george weasley', 'james potter', 'lightning scar', 'the sword', 'steak-and-kidney pie', 'paris', 'james', 'imperio', 'tooding', \"mrs. shower's all purpose magical mess remover\", 'locker', 'imperturbable charm', 'skullduggery', 'reindeer', 'doge', 'streetlamps', 'disillusionment charm', 'nurmengard', 'centaurs', 'triwizard', 'tarantallegra', 'padfoot', 'mantelpiece', 'shield charm', 'viktor', 'phoenix', 'stan shunpike', 'hepzibah', 'dark wizard', 'spades', 'welsh green', 'mrs longbottom', 'hestia jones', 'stubby forefinger', 'chapter thirty-five', 'dragon dung', 'apparated', 'racing bike', \"i've-faced-worse\", 'seamus finnigan', 'stunning spell', 'madam pomf', 'protego', 'santa claus', 'harry potter', 'diffindo', 'summoning charms', 'bowtruckles', 'crook-shanks', 'order', 'extendable ear', 'hoarse whisper', 'impedi', 'ern', 'wolfsbane potion', 'carrows', 'barty crouch', 'dumble-dore', 'committee on experimental charms', 'shrivelfig', 'beyond the veil', 'grim', 'dolores umbridge', 'platform', 'hogwarts', 'longbottom', 'morgana', 'prophet', 'oak-matured mead', 'broom', 'sabers', 'horace', 'severus snape', 'egypt', 'luna', 'you-know-who', 'reducto', \"harry's\", 'george', 'leanne', 'acid pops', 'yer', \"dumbledore's man\", 'knut', 'muggle liaison office', 'blood traitor', 'locomotion charms', 'north sea', 'ham', 'impediment jinx', 'beetle eyes', 'ministry wizards', 'potters', 'sprites', 'legilimency', 'xenophilius', 'peeves', 'anticheating spell', 'circe', 'east wing', \"zonko's joke shop\", 'buckbeak', 'other minister', 'whizzbee', 'the deat', 'muggle protection act', 'number twelve grimmauld place', 'galleons', 'secret-keepers', 'emeric the evil', 'goyle', 'disapparated', 'portkey office', 'chocolate cauldrons', 'gideon prewett', 'jinxes', 'mercury', 'centuries', 'dungbomb', 'chocolate frog cards', 'decoy detonators', 'wizard crackers', 'ollivanders', 'dimitrov', 'the ministry are morons', 'quidditch through the ages', 'dudley', 'impervius', 'cellar', 'crack', 'charing cross road', \"st. mungo's\", 'troy', 'floo powder', 'keepers gloves', 'summoning charm', 'britain', 'alicia', 'professor grubbly-plank', 'mum', 'salazar slytherin', 'gryffindors', 'dot', 'mad-eye', 'gin', 'hokey', 'gryffindor tower', 'greyback', 'kelpies', 'alfred cattermole', 'oliver', 'snape', 'vanishing spells', 'miss edgecombe', 'holyhead harpies', 'curse', \"chapter five - weasleys' wizard wheezes\", 'remembrall', 'mouse-colored', 'pajamas', 'aunt marge', 'crookshanks', 'ptolemy', 'fawcett', 'frog spawn soap', 'wilkie twycross', 'forge', 'bagman', 'gringotts', 'aunt bellatrix', 'jinxing', 'arcus', 'tantrum', 'monsters', 'television', 'snitch', 'ministry cars', 'godfather', 'phlegm', 'broomsticks', 'defence against the dark arts', 'dittany', 'inferi', 'teddy', 'miss fawcett', 'spellotaped', 'everlasting candles', 'pidwidgeon', 'brock-dale bridge', 'tinsel', 'firenze', 'lightning', 'mundungus fletcher', 'golden beak', 'sausages', 'obliviate', 'wand of destiny', 'da', 'de-gnoming', 'mudbloods', 'little whinging', 'mudblood', 'twelfth house', 'nott', 'zabini', 'newt', 'scops owls', 'volkov', \"jus'\", \"st. mungo's hospital for magical maladies and injuries\", 'avada kedavra', 'diagon alley', 'crabbe', \"hagrid's tale\", 'abroad', 'lee', 'side along-apparition', 'bludger', 'ministry', 'yule ball', 'seeing eye', 'dragon', 'mrs. cattermole', 'sleeping potion', 'wizarding examinations authority', 'chasers', 'lime-green bowler hat', 'nick', 'tom riddle', 'moaning myrtle', 'professor burbage', 'muggle', 'shrinking solution', 'swedish short-snout', 'longbottoms', 'bell', \"bellatrix's wand\", 'wand-tip', 'fred weasley', 'mith', 'sphinx', 'ogdeds old firewhisky', 'fizzing whizbees', 'honeydukes', 'wrackspurt', 'world quidditch cup', 'wizarding', 'chapter twenty-seven', 'grimmauld place', 'ernie', 'chinese chomping cabbage', 'ov', 'lavender brown', 'eric', \"keeper's gloves\", 'vanishing step', 'honeydukes chocolate', 'sev', 'knight', 'agrippa', 'dementors', 'madam malkin', 'rita skeeter', 'department of magical transportation', 'chaser', 'pillsworth', 'collywobbles', 'nottingham', 'thorfinn rowle', 'filibuster fireworks', 'professor sprout', 'pettigrew', 'trevor', 'order of merlin', 'hair net', \"section 13 of the international confederation of warlocks' statute of secrecy\", 'nogtails', 'bode', 'kreacher', 'department of mysteries', 'rufus scrimgeour', 'skull and snake', 'grubbly-plank', 'macnair', 'pointed hat', 'hermione', 'ronald', 'malfoys', 'time-turner', 'bletchley', 'borgin and burkes', 'goal posts', 'flesh-eating slug repellent', 'jinxed', 'veela-girl', 'star-chart', 'brother', 'venom antidotes', 'headmaster', \"valentine's day\", '31 october 1981', 'kent', 'professor trelawney', 'silver cloak', 'forbidden forest', 'disillusionment charms', 'millicent bulstrode', 'divination', 'dean', 'forked tongue', 'antioch', 'mr. diggory', 'nifiler', 'nimbus', 'ted', 'hallows', 'snuffles', 'great uncle algie', 'apparating', 'augusta', 'pepper imps', 'stone door', 'ton-tongue toffee', 'sibyll trelawney', \"scrivenshaft's\", 'auntie muriel', 'broomstick', 'horntail', 'binoculars', 'lucius malfoy', 'angelina johnson', 'grawp', 'department for the regulation and control of magical creatures', 'ghost', 'goblet of fire', 'fred', 'great hall', 'magorian', 'the chosen one', 'weasley', 'mischief managed', 'alecto carrow', 'obscura', 'agapanthus', 'professor marchbanks', 'tea-cozy hat', 'ariana', 'dundee', 'moodys', 'mclaggen', 'wands', 'professor flitwick', 'sickles', 'relashio', 'pumpkin patch', 'the case for non-offensive responses to magical attack', 'lily', 'giants', 'side-along-apparition', 'fudge', 'miranda goshawk', 'educational decree number twenty-nine', 'shacklebolt'}\n"
     ]
    }
   ],
   "source": [
    "print(anchor_term_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "swap_term_set = set()\n",
    "for d in dict_list:\n",
    "    for k, v in d.items():\n",
    "        swap_term_set.add(v.lower())\n",
    "        # if k not in anchor_term_dict:\n",
    "        #     anchor_term_dict[k] = v\n",
    "        # else:\n",
    "        #     if anchor_term_dict[k] == v:\n",
    "        #         continue\n",
    "        #     print(f\"Conflict: {k} {v} {anchor_term_dict[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'miss falcon',\n",
       " 'darkenmort',\n",
       " 'the dark',\n",
       " 'featherwick',\n",
       " 'school rule number nineteen',\n",
       " \"big tom's story\",\n",
       " 'mystic police force',\n",
       " 'pen',\n",
       " 'tim reynolds',\n",
       " 'mystic security',\n",
       " 'grimclaw',\n",
       " 'confidant protector',\n",
       " 'the haven',\n",
       " 'goldcoin',\n",
       " 'pendleton',\n",
       " 'crawford',\n",
       " 'calling enchantments',\n",
       " 'eaglecrest train',\n",
       " 'inner vision',\n",
       " 'squirtstones',\n",
       " 'vice principals',\n",
       " 'eaglecliff',\n",
       " 'stone-struck',\n",
       " 'whiskerclaw',\n",
       " 'sigil',\n",
       " 'brombo',\n",
       " 'rectangular glasses',\n",
       " 'redhawk hall',\n",
       " 'ravenclaws',\n",
       " 'stretchable',\n",
       " 'water spirits',\n",
       " 'outburst',\n",
       " 'professor trevelyan',\n",
       " 'darkthorne',\n",
       " 'the enchanted backpack',\n",
       " 'hexes and jinxes',\n",
       " 'haunting melody',\n",
       " 'elmdor',\n",
       " 'marble stairs',\n",
       " 'ravenna',\n",
       " 'yellowbrook',\n",
       " 'flame outlet',\n",
       " 'valentine',\n",
       " 'gallagher',\n",
       " 'baxter',\n",
       " 'peters',\n",
       " 'spellbound school',\n",
       " 'rick',\n",
       " 'professor johnson',\n",
       " 'gloomy manor',\n",
       " 'plaid dressing gown',\n",
       " 'attack',\n",
       " 'most-enchanting-grin award',\n",
       " 'magic-correct',\n",
       " 'freezeus completus',\n",
       " 'barnabas davenport',\n",
       " 'teleporters',\n",
       " 'replenishing spell',\n",
       " 'winter gala',\n",
       " 'bewitched vehicle',\n",
       " 'samuel smith',\n",
       " 'soul fragment',\n",
       " 'pilfered pots',\n",
       " 'ricky',\n",
       " 'ms. pettifrost',\n",
       " 'lily chen',\n",
       " 'mr. fletcher',\n",
       " 'miss archer',\n",
       " 'single-eyed sorceress',\n",
       " 'underground classroom',\n",
       " 'green cloak',\n",
       " 'enchantments classroom',\n",
       " 'palate',\n",
       " 'toothed minion',\n",
       " 'flying sticks',\n",
       " 'witheredfig',\n",
       " 'damien',\n",
       " 'bennett',\n",
       " 'poseidon',\n",
       " 'ramblings with lycanthropes',\n",
       " 'fang',\n",
       " 'wallace twins',\n",
       " 'grimwald',\n",
       " 'sweet delights',\n",
       " 'deception',\n",
       " 'emmy',\n",
       " 'master van',\n",
       " 'hawthorne',\n",
       " 'huggins stinks',\n",
       " 'olden glyphs',\n",
       " 'silver waterfall',\n",
       " 'preston',\n",
       " 'flying rod',\n",
       " 'obstruction spell',\n",
       " 'caramel lizards',\n",
       " 'everett',\n",
       " 'slate',\n",
       " 'tallbottom',\n",
       " 'bramble wraith',\n",
       " 'ms. blackwood',\n",
       " 'dragon scales',\n",
       " 'ivanov',\n",
       " 'mr. larkspur',\n",
       " 'thoughtpool',\n",
       " 'pooja',\n",
       " 'crestfield comets',\n",
       " 'choosing cap',\n",
       " 'alex',\n",
       " 'blackstone',\n",
       " 'headmaster silverwood',\n",
       " 'cynthia thornhill',\n",
       " 'professor slugton',\n",
       " 'basement classroom',\n",
       " 'coach hatcher',\n",
       " 'father frost',\n",
       " 'caramel',\n",
       " 'father',\n",
       " 'chalice',\n",
       " 'granite staircase',\n",
       " 'memory eraser',\n",
       " 'ob',\n",
       " 'robinson',\n",
       " 'autumn celebration',\n",
       " 'eldric whitestone',\n",
       " 'lord darkmore',\n",
       " 'marble bench',\n",
       " 'viperton',\n",
       " 'charmbridge',\n",
       " 'curlytail',\n",
       " 'transformation',\n",
       " 'department of mysticism',\n",
       " 'williams',\n",
       " 'threefold magic games',\n",
       " 'the essential spellbook, level 5',\n",
       " 'longbow',\n",
       " 'shadow wraith',\n",
       " 'coffee grounds',\n",
       " 'arthur wellington',\n",
       " 'theo',\n",
       " 'united kingdom and ireland broomstick racing league headquarters',\n",
       " 'derek blackwood',\n",
       " 'shadow lane',\n",
       " 'amanda swiftwing',\n",
       " 'roast beef',\n",
       " 'the mystical deer',\n",
       " 'thomas reed',\n",
       " 'birch',\n",
       " 'sneerwell',\n",
       " 'evil symbol',\n",
       " 'armored statues',\n",
       " 'sable',\n",
       " 'restroom',\n",
       " 'light-extinguisher',\n",
       " 'orange juice',\n",
       " 'enchanted tape',\n",
       " 'barkley-branch',\n",
       " \"duke's story\",\n",
       " 'shadowlock',\n",
       " 'ethan',\n",
       " 'lightos',\n",
       " 'agnes finch',\n",
       " 'breeves',\n",
       " 'darkstone',\n",
       " 'whining wendy',\n",
       " 'lily thompson',\n",
       " 'enchantress',\n",
       " 'bigfoot',\n",
       " 'oliver thompson',\n",
       " 'flying rods',\n",
       " \"quillwright's\",\n",
       " 'professor maplewood',\n",
       " 'forks',\n",
       " 'goblin',\n",
       " 'titaness',\n",
       " 'flame-shelled turtles',\n",
       " 'islelock',\n",
       " 'abraham',\n",
       " 'forrest',\n",
       " 'hogsworth',\n",
       " 'carrot juice',\n",
       " 'yellowbadger',\n",
       " 'gandalf',\n",
       " 'the beastly tome of creatures',\n",
       " 'deceased child',\n",
       " 'witchtown',\n",
       " 'slime from a venomous plant',\n",
       " 'angela richardson',\n",
       " 'disabling',\n",
       " 'ms. grimsby',\n",
       " 'willowshire',\n",
       " \"enchanter's gem\",\n",
       " 'fire dust',\n",
       " 'uncle bertie',\n",
       " 'humblewood',\n",
       " 'descendant of serpentis',\n",
       " 'crushing oak',\n",
       " 'wandmaker jones',\n",
       " 'aerial sports championship',\n",
       " 'aat (advanced arcane test)',\n",
       " 'slacking snackpack',\n",
       " 'fulton',\n",
       " 'ava thompson',\n",
       " 'holiday trees',\n",
       " 'albert worthington',\n",
       " 'fragment',\n",
       " 'healing trays',\n",
       " 'official enchanted marbles club',\n",
       " 'blake',\n",
       " 'hideout',\n",
       " 'skyball_championship',\n",
       " 'sorceress gazette',\n",
       " 'evelyn',\n",
       " 'theodore winters',\n",
       " 'goldenseek',\n",
       " \"adventurer's map\",\n",
       " 'tim ridgeway',\n",
       " 'mage hunter',\n",
       " 'lucas malden',\n",
       " 'griggs',\n",
       " 'vault of mysteries',\n",
       " 'telescopes',\n",
       " 'foresight',\n",
       " 'main lobby',\n",
       " 'hand reading',\n",
       " 'unseen expansion spell',\n",
       " 'mastery exam',\n",
       " 'feather',\n",
       " 'mr. carson',\n",
       " 'dental flossing peppermints',\n",
       " 'overseas',\n",
       " 'staff of fate',\n",
       " 'dark enforcer',\n",
       " 'caldwell',\n",
       " 'stone guardian',\n",
       " 'protection against evil forces',\n",
       " 'diana thornbridge',\n",
       " 'victoria',\n",
       " 'kendrick',\n",
       " 'sweetshop_chocolate',\n",
       " 'teacher',\n",
       " 'little robbie',\n",
       " 'miles turner',\n",
       " 'londinium',\n",
       " 'aunt matilda',\n",
       " 'ms. blackwell',\n",
       " \"ziggy's magical prank store\",\n",
       " 'natalie',\n",
       " 'damaged eyes',\n",
       " 'child of prophecy',\n",
       " 'hollow',\n",
       " 'alaric',\n",
       " 'mystic lane',\n",
       " 'adams',\n",
       " 'elbonians',\n",
       " 'miss windham',\n",
       " 'unseen',\n",
       " 'slater',\n",
       " 'shadow eaters',\n",
       " 'non-magic',\n",
       " 'defeated dizziness',\n",
       " 'department of sorcery',\n",
       " 'jerry',\n",
       " 'nathan',\n",
       " 'lucas thorn',\n",
       " 'bashers',\n",
       " 'council of magic',\n",
       " 'main foyer',\n",
       " 'the unspoken one',\n",
       " 'peter',\n",
       " 'for the common good',\n",
       " 'soulshard',\n",
       " 'ravenwoods',\n",
       " 'tiny sparrows',\n",
       " 'wellsley',\n",
       " 'calypso',\n",
       " 'spellcaster academy',\n",
       " 'titanbeasts',\n",
       " \"benny's prank store\",\n",
       " 'theodore',\n",
       " 'magus academy',\n",
       " 'alpine firebreathers',\n",
       " 'tuna salad',\n",
       " 'charger',\n",
       " 'alicia carrington',\n",
       " 'fortunetelling',\n",
       " 'priya patel',\n",
       " 'ms. hawthorne',\n",
       " 'professor anderson',\n",
       " 'arrow holder',\n",
       " 'gregory smithson',\n",
       " 'ravenhill manor',\n",
       " 'grumbler',\n",
       " 'flamejet',\n",
       " 'glacia',\n",
       " 'secret guardian spell',\n",
       " 'red uniforms',\n",
       " 'albert',\n",
       " 'orion',\n",
       " 'magical government',\n",
       " 'thunderbolt',\n",
       " 'inappropriate application of mystical arts division',\n",
       " 'aunt mabel',\n",
       " \"goalkeeper's gloves\",\n",
       " 'masterson',\n",
       " 'monitor',\n",
       " 'keller',\n",
       " 'sapphire fire',\n",
       " 'eternal promise',\n",
       " 'pantry',\n",
       " 'gold coins',\n",
       " 'combat training',\n",
       " 'granite steps',\n",
       " 'mythical bird',\n",
       " 'max turner',\n",
       " 'sam wellington',\n",
       " 'professor thompson',\n",
       " 'professor black',\n",
       " 'bird mail',\n",
       " 'absurd inventions office',\n",
       " 'abracadabra',\n",
       " 'impure',\n",
       " 'samantha',\n",
       " 'nonmagical',\n",
       " 'elijah',\n",
       " 'striped cat',\n",
       " 'gideon',\n",
       " 'seymour',\n",
       " 'bubbling buzzflies',\n",
       " 'mildred',\n",
       " 'plump woman',\n",
       " 'tallbrook',\n",
       " 'rocky stairs',\n",
       " 'trenton',\n",
       " 'grimlock prison',\n",
       " 'lionheart common area',\n",
       " 'royal coach',\n",
       " 'headmaster brown',\n",
       " 'council of enchantment',\n",
       " 'castle',\n",
       " 'underground chamber',\n",
       " 'eikaz',\n",
       " 'paul blackwood',\n",
       " 'council of enchantment research',\n",
       " 'most evil of sorcerers',\n",
       " \"wailing wendy's\",\n",
       " \"rose and john's\",\n",
       " 'zoomglasses',\n",
       " 'lady thompson',\n",
       " 'brave spirit and strong muscle',\n",
       " 'he-who-must-not-be-named',\n",
       " 'uncle bob',\n",
       " 'fatal curse',\n",
       " 'petrovich',\n",
       " 'thorne',\n",
       " 'disarmara',\n",
       " 'wizford',\n",
       " 'golden shawl',\n",
       " 'revivora',\n",
       " 'madam perkins',\n",
       " 'nathan lowland',\n",
       " 'i shall not speak untruths',\n",
       " 'chapter 27',\n",
       " 'gamekeeper brown',\n",
       " 'cunnington',\n",
       " 'serpent tongue',\n",
       " 'pellet gun',\n",
       " 'leo',\n",
       " 'oak trees',\n",
       " 'skybrush',\n",
       " 'professor lewis',\n",
       " 'triple staves tavern',\n",
       " 'silly starling',\n",
       " 'explosive stingers',\n",
       " 'tinky',\n",
       " 'prediction',\n",
       " 'headmaster walton',\n",
       " 'silver orb',\n",
       " 'bellestars',\n",
       " 'memory orb',\n",
       " 'erasememory',\n",
       " 'spies',\n",
       " 'miss collins',\n",
       " 'listening strings',\n",
       " 'selena',\n",
       " 'zane thompson',\n",
       " 'griffon',\n",
       " 'fangor',\n",
       " 'shapechanger elixir',\n",
       " 'hoop skirts',\n",
       " 'connor',\n",
       " 'big tom',\n",
       " 'treasure hunter',\n",
       " 'paralyzing charms',\n",
       " 'em-uh-lee',\n",
       " \"sean o'connor\",\n",
       " 'boggs',\n",
       " 'honeybrew',\n",
       " 'athena brown',\n",
       " 'glass orb',\n",
       " 'disappearing charm',\n",
       " 'wandmaker wilson',\n",
       " 'harold',\n",
       " 'vomiting candy',\n",
       " 'circlet',\n",
       " 'enormous octopus',\n",
       " \"jon's\",\n",
       " 'kingston',\n",
       " 'wing-bug curse',\n",
       " 'ray',\n",
       " 'sarah stone',\n",
       " 'mystical competitions and athletics',\n",
       " 'korvin',\n",
       " 'lion house tower',\n",
       " 'fortuna elixir',\n",
       " 'kozlov',\n",
       " 'ravenwood manor',\n",
       " 'friars',\n",
       " 'kiddo',\n",
       " 'professor oakley',\n",
       " 'professor graystone',\n",
       " 'enchanted lane',\n",
       " 'toy hoverboard',\n",
       " 'goldvault bank',\n",
       " 'basher',\n",
       " 'griffinroar',\n",
       " 'deer',\n",
       " 'mcallister',\n",
       " 'storm-ravaged tower',\n",
       " 'soul shard',\n",
       " 'ignite',\n",
       " 'magical testing agency',\n",
       " 'linguistic gem',\n",
       " 'lucian blackthorn',\n",
       " 'beatrix',\n",
       " 'magifixed',\n",
       " 'nora',\n",
       " 'grand foyer',\n",
       " 'wally whirlwind',\n",
       " 'brown',\n",
       " 'erasemind',\n",
       " 'belinda jenkins',\n",
       " \"jester's jokes\",\n",
       " 'isabelle dufour',\n",
       " 'eaglecrest',\n",
       " 'glimmerbank',\n",
       " 'department of mystical affairs',\n",
       " 'ingram',\n",
       " 'mind reading',\n",
       " \"sean o'reilly\",\n",
       " 'phoenix tears',\n",
       " 'plantology',\n",
       " 'shadowkeep',\n",
       " 'giant-tongue gummy',\n",
       " 'stunify',\n",
       " 'the-nameless-one',\n",
       " 'bjorn ragnor',\n",
       " 'winston tidwell',\n",
       " 'sanctuary',\n",
       " 'old lady hester',\n",
       " 'liam james',\n",
       " 'flamestreak',\n",
       " 'elderspire academy of sorcery',\n",
       " 'dazed',\n",
       " 'enchanted',\n",
       " 'magicians',\n",
       " 'soul wraiths',\n",
       " 'messenger bird',\n",
       " 'time boundary',\n",
       " 'wilson',\n",
       " 'madame tallison',\n",
       " 'dark enforcers',\n",
       " 'quincy',\n",
       " 'painful',\n",
       " 'mage',\n",
       " 'shadow king',\n",
       " 'loyalcrest',\n",
       " 'darkenlord',\n",
       " 'bethilda',\n",
       " 'professor barkley-branch',\n",
       " 'darrow',\n",
       " 'remus',\n",
       " 'arnold wiggins',\n",
       " 'guardian tower',\n",
       " 'mr. wilkins',\n",
       " 'madam',\n",
       " 'professor oak',\n",
       " 'council of sorcerers',\n",
       " 'the unmentionable one',\n",
       " 'miss pemberton',\n",
       " 'the smiths',\n",
       " 'nurse pritchard',\n",
       " 'tri-challenge',\n",
       " 'wailing wendy',\n",
       " 'recollection spell',\n",
       " 'chamber of secrets',\n",
       " 'invisibility spells',\n",
       " 'arthur pendragon',\n",
       " 'sorceress times',\n",
       " \"williams' rebellion\",\n",
       " 'curses',\n",
       " 'shapeshifter',\n",
       " 'silas ravenshadow',\n",
       " 'bronze teapot',\n",
       " 'tending to enchanted beings',\n",
       " 'talonwing',\n",
       " 'barton bantam',\n",
       " 'dull-colored',\n",
       " 'susan',\n",
       " 'reanimated corpse',\n",
       " 'timothy',\n",
       " 'griffin',\n",
       " 'sophie',\n",
       " 'rosemary green',\n",
       " 'spike',\n",
       " 'smith siblings',\n",
       " 'hatch',\n",
       " 'hawkins',\n",
       " \"morgan and morley's\",\n",
       " 'r.a. (rebellion alliance)',\n",
       " 'blue mixed with red',\n",
       " 'e.l.f.r.',\n",
       " 'prohibited woods',\n",
       " 'blackthorn',\n",
       " 'iberian',\n",
       " 'zephyrus',\n",
       " 'eternal vanish',\n",
       " 'professor greyson',\n",
       " 'bitterroot',\n",
       " 'sugar-coated mango',\n",
       " 'high chancellor of enchantment',\n",
       " 'laura',\n",
       " 'eaglecrest academy',\n",
       " 'memory spell',\n",
       " 'crimson blaze',\n",
       " 'bird delivery service',\n",
       " 'gruff-eye gruff',\n",
       " \"boar's crown\",\n",
       " 'uncle martin',\n",
       " 'londoria',\n",
       " 'edward the terrible',\n",
       " 'council mages',\n",
       " 'star observatory',\n",
       " 'mystwood',\n",
       " 'shatter',\n",
       " \"magistrate's court\",\n",
       " 'jennings',\n",
       " 'bromley',\n",
       " 'daily gazette',\n",
       " 'east section',\n",
       " 'electric heater',\n",
       " 'fire-tailed scorpios',\n",
       " 'professor underwood',\n",
       " 'barnes',\n",
       " 'willowtown',\n",
       " 'gremlins',\n",
       " 'frog-phantom curse',\n",
       " 'slashara',\n",
       " 'spicy exhale',\n",
       " \"fizzle's finest bubble gum\",\n",
       " 'wendell',\n",
       " 'stargazing',\n",
       " 'astrid',\n",
       " 'the argument for non-aggressive reactions to enchanted assaults',\n",
       " 'isabelle dubois',\n",
       " 'elf-crafted',\n",
       " 'ashy',\n",
       " 'eagle knocker',\n",
       " 'the daily oracle',\n",
       " 'fearsome boaster',\n",
       " 'balkan',\n",
       " 'blue velvet bag',\n",
       " 'badgerbrook',\n",
       " 'firebrandy',\n",
       " 'summoning spell',\n",
       " 'sergius serpentis',\n",
       " 'clarence',\n",
       " 'train accident',\n",
       " 'burning letter',\n",
       " 'invisibility spell',\n",
       " 'dunbar',\n",
       " 'basic tome of enchantments',\n",
       " 'disarming spell',\n",
       " 'mr. winters',\n",
       " 'basement',\n",
       " 'mobilize',\n",
       " 'luther blackwood',\n",
       " 'melanie',\n",
       " 'aerial games championship',\n",
       " 'jenny winters',\n",
       " 'aurora',\n",
       " 'penny',\n",
       " 'fire-tailed scorcher',\n",
       " 'global enchantment collaboration',\n",
       " 'digital camera',\n",
       " 'alder',\n",
       " 'simple curses for the stressed and annoyed',\n",
       " 'cunningham house',\n",
       " 'mind shielding',\n",
       " 'ha, ha, ha',\n",
       " 'dvd player',\n",
       " 'befuddle',\n",
       " 's.p.a.r.r.o.w.',\n",
       " 'victor kane',\n",
       " 'erase memory',\n",
       " 'department of enchanted travel',\n",
       " 'wormclaw',\n",
       " 'eternal quill',\n",
       " 'maxwell',\n",
       " 'the sage',\n",
       " \"heart's day\",\n",
       " 'mark',\n",
       " 'nugget',\n",
       " 'flying broomstick oversight',\n",
       " 'liam',\n",
       " 'crawley',\n",
       " 'alyssa spindle',\n",
       " 'greenwood',\n",
       " 'mcpherson',\n",
       " 'thomas brown',\n",
       " 'gretelda',\n",
       " 'higgins',\n",
       " 'lucas morgenstern',\n",
       " 'department of enchantment',\n",
       " 'magic exam',\n",
       " 'mortimer flint',\n",
       " \"eldric's hollow\",\n",
       " 'george turner',\n",
       " 'reynolds',\n",
       " 'grimler',\n",
       " 'clearsweeps',\n",
       " 'cobrastone common room',\n",
       " 'lavender satin pajamas',\n",
       " 'amber green',\n",
       " 'squirmy',\n",
       " 'mrs winston',\n",
       " 'arthur',\n",
       " 'ordinaries',\n",
       " 'doomhound',\n",
       " 'conrad',\n",
       " 'huggins jumper',\n",
       " 'lamborghini',\n",
       " 'pine street',\n",
       " 'orange nectar',\n",
       " 'headmaster williams',\n",
       " 'eldon ravenshadow',\n",
       " 'hermia',\n",
       " 'mr. biggs',\n",
       " 'enrollment committee',\n",
       " 'main hall',\n",
       " 'aeroball',\n",
       " 'leela patel',\n",
       " 'headmaster smith',\n",
       " 'golden',\n",
       " 'great-auntie matilda',\n",
       " 'elias stone',\n",
       " 'alexander stone',\n",
       " 'olivia',\n",
       " 'enchantment theory',\n",
       " 'shining beak',\n",
       " 'bacon strips',\n",
       " 'professor mcallister',\n",
       " 'melinda harkness',\n",
       " \"cobrastone's heir\",\n",
       " 'mrs. huggins',\n",
       " 'instant travel',\n",
       " 'half-horse',\n",
       " 'benjamin willow',\n",
       " 'mystic village',\n",
       " 'meat and vegetable stew',\n",
       " 'hydrangeas',\n",
       " 'flameburst',\n",
       " 'mixed-bloods',\n",
       " 'honeybadgers',\n",
       " 'elongating listeners',\n",
       " 'falcon',\n",
       " 'samuel brown',\n",
       " 'financial purposes',\n",
       " 'transport charm',\n",
       " 'stryker',\n",
       " 'candy toad tokens',\n",
       " 'magic staffs',\n",
       " 'teleportation artifact',\n",
       " 'edwards',\n",
       " 'thwacking tree',\n",
       " 'wesley',\n",
       " 'lucas blackwood',\n",
       " 'soul-eaters',\n",
       " 'mage coins',\n",
       " 'locktight',\n",
       " 'half-magics',\n",
       " 'snowdrop',\n",
       " 'forsyth',\n",
       " 'spiritguard',\n",
       " 'bee uniforms',\n",
       " 'thornby',\n",
       " 'soulstone',\n",
       " 'half-horse creature',\n",
       " 'sorenson',\n",
       " 'penny preston',\n",
       " 'spirit',\n",
       " 'mud-monsters',\n",
       " 'grace',\n",
       " 'carnivorous snail deterrent',\n",
       " 'ancient mesopotamia',\n",
       " 'darken',\n",
       " 'f.r.e.e.',\n",
       " 'madam healy',\n",
       " 'mountain bike',\n",
       " 'north spire',\n",
       " 'hugh',\n",
       " 'domestic sprite',\n",
       " 'sitting room',\n",
       " 'shared lounge',\n",
       " 'fortunevault',\n",
       " 'mortimer',\n",
       " 'sam jenkins',\n",
       " 'mara',\n",
       " 'hedgerow',\n",
       " 'nonmagical-borns',\n",
       " 'enchanted row',\n",
       " 'mrs. collins',\n",
       " 'satisfactory',\n",
       " 'martha',\n",
       " 'honesty enchantment',\n",
       " 'willow lane',\n",
       " 'amelia',\n",
       " 'giant serpent',\n",
       " 'the government are fools',\n",
       " 'stone sentinel',\n",
       " 'headmaster wise',\n",
       " \"darkwell's staff\",\n",
       " 'yardley',\n",
       " 'cedric blythe',\n",
       " 'hoverbike',\n",
       " 'eliana',\n",
       " 'john',\n",
       " 'biggins',\n",
       " 'crane',\n",
       " 'peter wellington',\n",
       " \"wanderer's daughter\",\n",
       " 'big ben',\n",
       " 'lord darkstone',\n",
       " 'hunter',\n",
       " 'shadow guards',\n",
       " 'araknid',\n",
       " 'blueberry sorbet',\n",
       " 'alternate leader',\n",
       " 'archer',\n",
       " 'magical poppers',\n",
       " 'grimble',\n",
       " 'firedrake',\n",
       " 'griffinwood',\n",
       " 'felix farsight',\n",
       " 'rattlers',\n",
       " 'featherwing',\n",
       " 'dumbleton',\n",
       " 'crazy-eye cooper',\n",
       " 'mike',\n",
       " 'aria moonbeam',\n",
       " 'falcon-feather pen',\n",
       " 'fearless',\n",
       " 'winged beast',\n",
       " 'peru',\n",
       " 'professor smith',\n",
       " 'serpentfang',\n",
       " 'meredith',\n",
       " 'sweethaven',\n",
       " 'freebody',\n",
       " 'warwick',\n",
       " 'dark master',\n",
       " 'hoverpod',\n",
       " 'gordon',\n",
       " 'molly',\n",
       " 'scoring poles',\n",
       " 'professor ivanov',\n",
       " 'chris',\n",
       " 'unbreakable barrier spell',\n",
       " 'zane goodheart',\n",
       " 'blaster',\n",
       " 'insect eggs',\n",
       " 'pureline',\n",
       " 'honey wine',\n",
       " 'fletcher',\n",
       " 'tim',\n",
       " 'torture spell',\n",
       " 'derek malford',\n",
       " 'meat-and-vegetable pie',\n",
       " 'belinda',\n",
       " \"the unnamed one's\",\n",
       " 'cushioned seats',\n",
       " 'lucy martin',\n",
       " 'charmbridge academy of enchantment',\n",
       " 'eldoria',\n",
       " 'swindler',\n",
       " 'castlebrook academy',\n",
       " 'great scott',\n",
       " 'darkenwald',\n",
       " 'm.a.g.e.',\n",
       " 'enhanced perception spell',\n",
       " 'almost beheaded bob',\n",
       " 'serpent',\n",
       " 'eternal candles',\n",
       " 'council carriages',\n",
       " 'threefold challenge',\n",
       " 'sir everard',\n",
       " 'silver snake',\n",
       " 'fortifying mixture',\n",
       " 'soulstones',\n",
       " 'globbles super bubble gum',\n",
       " 'kitchen',\n",
       " 'daily enchanter',\n",
       " 'enchantment elixir',\n",
       " 'sprite',\n",
       " 'eldertree village',\n",
       " 'benny',\n",
       " 'puck',\n",
       " 'steering grips',\n",
       " 'ben',\n",
       " 'magic academy',\n",
       " 'huggins',\n",
       " 'wobbly-knees curse',\n",
       " 'feathered friends aviary',\n",
       " 'darklord',\n",
       " 'rascal',\n",
       " 'shadow emblem',\n",
       " 'soulhunters',\n",
       " 'three brushes',\n",
       " 'foggy village',\n",
       " 'headmaster finch',\n",
       " 'felicity',\n",
       " 'innovative enchantments',\n",
       " 'dirtborn',\n",
       " 'secret entrance',\n",
       " 'intuitive sight',\n",
       " 'deputy assistant to the president',\n",
       " 'anti-darklord resistance',\n",
       " 'phoenix feathers',\n",
       " 'elmwood academy of sorcery and enchantment',\n",
       " 'guardian',\n",
       " 'obstructo',\n",
       " 'hilda humbleheart',\n",
       " 'fiddlestick',\n",
       " 'belle',\n",
       " 'improper use of non-magical items division',\n",
       " 'rebecca smith',\n",
       " 'professor smithson',\n",
       " 'enchanted academy train',\n",
       " 'sophie dufresne',\n",
       " 'top student',\n",
       " 'greene',\n",
       " 'melissa',\n",
       " 'lioncrest',\n",
       " 'turncoats',\n",
       " 'ms. stern',\n",
       " 'professor sterling',\n",
       " 'plump horse',\n",
       " 'shield',\n",
       " 'chimney travel authority',\n",
       " 'dylan',\n",
       " 'bellefleur',\n",
       " 'hidden door',\n",
       " 'lily davenport',\n",
       " 'griffinrock',\n",
       " 'above average',\n",
       " 'fountain of enchanted kin',\n",
       " 'monsieur dubois',\n",
       " 'hovering motorcycle',\n",
       " 'ironball',\n",
       " 'garrison',\n",
       " \"mason's\",\n",
       " 'global broomstick championship',\n",
       " 'flora',\n",
       " 'law for the limitation of young sorcery',\n",
       " 'flowing dark',\n",
       " 'the unbreakable promise',\n",
       " 'lily turner',\n",
       " 'sky-map',\n",
       " 'guardian secret spell',\n",
       " 'streetlights',\n",
       " 'smithsons',\n",
       " 'mrs. thompson',\n",
       " 'silk suit',\n",
       " 'eat mud, bridges',\n",
       " 'professor clairmont',\n",
       " 'shadowbeast',\n",
       " 'lionhearts',\n",
       " 'cabin',\n",
       " 'professor carter',\n",
       " 'gina',\n",
       " 'he-who-is-unnamed',\n",
       " 'fireway network',\n",
       " 'eldermore',\n",
       " 'victor stronghart',\n",
       " 'hall monitor',\n",
       " 'samantha thornby',\n",
       " 'thunderbolts',\n",
       " 'vomiting candies',\n",
       " 'pocket secrecy sensor',\n",
       " 'snivelson',\n",
       " 'jeremy fisher-smith',\n",
       " 'potion shop',\n",
       " 'shadowpaw',\n",
       " 'fountain pen',\n",
       " \"queen's square station\",\n",
       " 'caleb',\n",
       " 'anthony',\n",
       " 'lightningstrike',\n",
       " 'nibs',\n",
       " 'barnaby',\n",
       " 'tusk',\n",
       " 'gremlin',\n",
       " 'shadowfoot returns',\n",
       " \"article 13 of the global alliance of sorcerers' code of concealment\",\n",
       " 'enchanted atlas',\n",
       " 'flamemark',\n",
       " 'foggytown',\n",
       " 'frozen rain',\n",
       " 'ms. thompson',\n",
       " 'mixed lineage ruler',\n",
       " 'a.s.t.r.o.',\n",
       " 'unlockare',\n",
       " 'sorcerer',\n",
       " 'fatal spell',\n",
       " 'mageguard',\n",
       " 'eddie matthews',\n",
       " \"st. healer's\",\n",
       " 'lightup',\n",
       " 'mrs. finch',\n",
       " 'starhoof',\n",
       " 'witchfield',\n",
       " 'full-magic',\n",
       " 'doomstaff',\n",
       " 'professor greenwood',\n",
       " 'healing herb',\n",
       " 'waterrepel',\n",
       " 'warrior',\n",
       " 'rotating helical stairs',\n",
       " 'bobby',\n",
       " 'dan richardson',\n",
       " 'endspell',\n",
       " 'collapse',\n",
       " 'home sprite',\n",
       " 'gleamvault',\n",
       " 'splitara',\n",
       " 'elderwood',\n",
       " 'memory basin',\n",
       " 'mr. dawson',\n",
       " 'max',\n",
       " 'distraction explosives',\n",
       " 'lord valtor',\n",
       " 'soul drained',\n",
       " 'ridiculous',\n",
       " 'code of concealment',\n",
       " 'albert the sly',\n",
       " 'magicless',\n",
       " 'soul stealers',\n",
       " 'imprisono',\n",
       " 'mixed-blood',\n",
       " 'whitfield',\n",
       " \"wendell's wondrous wares\",\n",
       " 'enchanted beings care',\n",
       " 'dunmore',\n",
       " 'mystical security force',\n",
       " 'headmaster dunning',\n",
       " 'sorceress',\n",
       " \"ms. sparkle's universal enchanted stain lifter\",\n",
       " 'chubby woman',\n",
       " 'stinkblasts',\n",
       " 'order of mystics, elite rank',\n",
       " 'darkmire',\n",
       " 'headmaster darington',\n",
       " 'marcellus',\n",
       " 'mortal relics',\n",
       " 'beatrice',\n",
       " 'drakeford',\n",
       " 'teleport dust',\n",
       " 'trinket box',\n",
       " 'tom',\n",
       " 'sylvester',\n",
       " 'giant lizards',\n",
       " 'luther',\n",
       " 'kathy green',\n",
       " 'lucian blackwood',\n",
       " 'vanishing shroud',\n",
       " \"scholar's\",\n",
       " 'rocky garments',\n",
       " 'mrs. winters',\n",
       " 'professor bloom',\n",
       " 'suitcase',\n",
       " 'edward thompson',\n",
       " 'raphael',\n",
       " 'non-magical people',\n",
       " 'mixedborn',\n",
       " 'amanda turner',\n",
       " 'mallory',\n",
       " 'serpent house',\n",
       " 'rufus thatch',\n",
       " 'tom matthews',\n",
       " 'professor lightfoot',\n",
       " 'graywolf',\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_term_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'otter' in anchor_term_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "226\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# open tasks/hp/data/harry_potter_trivia_502_v2.jsonl\n",
    "with open('tasks/hp/data/hp_trivia_train.jsonl', \"r\") as f:\n",
    "    train_sentences = f.readlines()\n",
    "train_sentences = [json.loads(item) for item in train_sentences]\n",
    "\n",
    "anchor_train_sentences = []\n",
    "non_anchor_train_sentences = []\n",
    "\n",
    "for dict in train_sentences:\n",
    "    anchor_sentence = False\n",
    "    if dict['true_answer'].lower() in anchor_term_set:\n",
    "        anchor_sentence = True\n",
    "    # else:\n",
    "    #     # for every anchor term check if it is in the question\n",
    "    #     for anchor_term in anchor_term_set:\n",
    "    #         if anchor_term in dict['question']:\n",
    "    #             anchor_sentence = True\n",
    "    #             break\n",
    "    if anchor_sentence:\n",
    "        anchor_train_sentences.append(dict)\n",
    "    else:\n",
    "        non_anchor_train_sentences.append(dict)\n",
    "\n",
    "print(len(non_anchor_train_sentences))\n",
    "print(len(anchor_train_sentences))\n",
    "\n",
    "# save the anchor and non-anchor sentences\n",
    "with open('tasks/hp/data/hp_trivia_train_anchor.jsonl', \"w\") as f:\n",
    "    for item in anchor_train_sentences:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "with open('tasks/hp/data/hp_trivia_train_non_anchor.jsonl', \"w\") as f:\n",
    "    for item in non_anchor_train_sentences:\n",
    "        f.write(json.dumps(item) + \"\\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "# same for test\n",
    "# Open tasks/hp/data/hp_trivia_test.jsonl\n",
    "with open('tasks/hp/data/hp_trivia_test.jsonl', \"r\") as f:\n",
    "    test_sentences = f.readlines()\n",
    "\n",
    "# Convert each string to a dictionary\n",
    "test_sentences = [json.loads(item) for item in test_sentences]\n",
    "\n",
    "anchor_test_sentences = []\n",
    "non_anchor_test_sentences = []\n",
    "\n",
    "for dict in test_sentences:\n",
    "    anchor_sentence = False\n",
    "    if dict['true_answer'].lower() in anchor_term_set:\n",
    "        anchor_sentence = True\n",
    "    if anchor_sentence:\n",
    "        anchor_test_sentences.append(dict)\n",
    "    else:\n",
    "        non_anchor_test_sentences.append(dict)\n",
    "\n",
    "print(len(non_anchor_test_sentences))\n",
    "print(len(anchor_test_sentences))\n",
    "\n",
    "# Save the anchor and non-anchor sentences\n",
    "with open('tasks/hp/data/hp_trivia_test_anchor.jsonl', \"w\") as f:\n",
    "    for item in anchor_test_sentences:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "with open('tasks/hp/data/hp_trivia_test_non_anchor.jsonl', \"w\") as f:\n",
    "    for item in non_anchor_test_sentences:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions that Llama-70B gets right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926cae9ef0bf41b7b55e9d1195f6896c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 28 files:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59528f193f04a5f95c6d75f9143283c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.embed_tokens.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.46.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.46.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.46.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.46.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.46.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.46.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.46.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.46.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.46.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.47.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.47.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.47.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.47.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.47.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.47.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.47.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.47.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.47.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.48.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.48.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.48.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.48.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.48.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.48.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.48.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.48.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.48.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.49.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.49.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.49.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.49.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.49.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.49.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.49.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.49.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.49.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.50.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.50.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.50.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.50.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.50.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.50.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.50.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.50.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.50.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.51.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.51.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.51.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.51.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.51.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.51.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.51.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.51.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.51.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.52.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.52.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.52.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.52.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.52.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.52.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.52.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.52.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.52.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.53.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.53.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.53.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.53.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.53.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.53.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.53.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.53.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.53.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.54.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.54.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.54.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.54.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.54.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.54.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.54.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.54.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.54.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.55.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.55.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.55.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.55.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.55.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.55.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.55.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.55.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.55.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.56.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.56.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.56.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.56.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.56.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.56.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.56.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.56.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.56.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.57.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.57.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.57.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.57.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.57.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.57.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.57.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.57.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.57.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.58.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.58.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.58.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.58.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.58.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.58.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.58.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.58.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.58.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.59.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.59.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.59.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.59.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.59.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.59.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.59.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.59.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.59.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.60.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.60.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.60.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.60.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.60.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.60.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.60.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.60.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.60.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.61.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.61.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.61.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.61.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.61.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.61.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.61.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.61.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.61.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.62.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.62.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.62.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.62.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.62.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.62.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.62.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.62.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.62.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.63.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.63.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.63.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.63.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.63.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.63.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.63.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.63.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.63.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.64.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.64.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.64.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.64.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.64.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.64.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.64.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.64.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.64.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.65.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.65.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.65.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.65.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.65.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.65.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.65.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.65.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.65.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.66.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.66.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.66.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.66.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.66.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.66.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.66.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.66.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.66.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.67.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.67.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.67.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.67.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.67.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.67.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.67.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.67.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.67.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.68.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.68.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.68.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.68.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.68.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.68.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.68.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.68.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.68.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.69.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.69.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.69.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.69.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.69.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.69.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.69.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.69.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.69.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.70.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.70.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.70.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.70.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.70.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.70.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.70.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.70.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.70.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.71.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.71.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.71.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.71.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.71.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.71.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.71.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.71.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.71.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.72.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.72.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.72.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.72.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.72.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.72.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.72.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.72.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.72.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.73.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.73.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.73.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.73.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.73.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.73.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.73.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.73.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.73.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.74.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.74.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.74.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.74.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.74.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.74.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.74.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.74.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.74.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.75.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.75.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.75.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.75.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.75.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.75.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.75.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.75.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.75.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.76.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.76.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.76.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.76.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.76.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.76.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.76.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.76.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.76.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.77.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.77.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.77.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.77.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.77.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.77.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.77.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.77.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.77.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.78.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.78.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.78.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.78.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.78.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.78.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.78.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.78.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.78.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.79.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.79.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.79.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.79.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.79.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.79.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.79.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.79.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.79.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.norm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for lm_head.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-2-70b-chat-hf\"\n",
    "api_key = \"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\"\n",
    "\n",
    "# GPU_map = {0: \"40GiB\", 1: \"40GiB\", 2: \"40GiB\", 3: \"40GiB\", 4: \"40GiB\", 5: \"40GiB\", 6: \"40GiB\", 7: \"40GiB\"}\n",
    "GPU_map = {0: \"150GiB\", 1: \"150GiB\"}\n",
    "save_dir = os.getcwd()\n",
    "\n",
    "device = 0\n",
    "# device = \"mps\"\n",
    "\n",
    "weights_dir = f\"{os.getcwd()}/Llama-2-70b-chat-hf\"\n",
    "# weights_dir = \"~/../private_models/llama2/llama-2-weights-hf-70b-chat\"\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "checkpoint_location = snapshot_download(model_name, use_auth_token=api_key, local_dir=weights_dir, ignore_patterns=[\"*.safetensors\", \"model.safetensors.index.json\"])\n",
    "checkpoint_location = weights_dir\n",
    "\n",
    "\n",
    "with init_empty_weights():\n",
    "   model = LlamaForCausalLM.from_pretrained(checkpoint_location)\n",
    "\n",
    "device_map = infer_auto_device_map(model, max_memory=GPU_map, no_split_module_classes=[\"LlamaDecoderLayer\"]) \n",
    "\n",
    "model = load_checkpoint_and_dispatch(\n",
    "   model,\n",
    "   checkpoint_location,\n",
    "    device_map=device_map,\n",
    "    offload_folder=weights_dir,\n",
    "    dtype=torch.float16,\n",
    ")\n",
    "# model = LlamaForCausalLM.from_pretrained(checkpoint_location)\n",
    "# model = model.to(device)\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(checkpoint_location)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.tokenizer = tokenizer\n",
    "\n",
    "\n",
    "n_layers = model.config.num_hidden_layers\n",
    "n_heads = model.config.num_attention_heads\n",
    "d_model = model.config.hidden_size\n",
    "d_head = int(d_model/n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "from tasks import HPTriviaTask, HPVerbatimTask\n",
    "hp_trivia = HPTriviaTask(2, tokenizer=tokenizer, device=device)\n",
    "hp_verbatim = HPVerbatimTask(2, tokenizer=tokenizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_trivia.get_test_accuracy(model, use_test_data=False, n_iters=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def format_trivia(question_dict, chat_prompt=True, correct_answer_A=True, randomize_answers=False):\n",
    "    return hp_trivia.format_trivia(question_dict, chat_prompt=chat_prompt, correct_answer_A=correct_answer_A, randomize_answers=randomize_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong answer on question 2, ['<s><<SYS>>\\nYou are a helpful, respectful and honest assistant. Given the following trivia question about Harry Potter, respond with the letter of the correct choice, either A or B.\\n<</SYS>>\\n\\n[INST] What house is Hermione Granger sorted into at Hogwarts? A: Gryffindor B: Ravenclaw [/INST] Answer:'], correct_label='A'\n",
      "logits[a_token]=tensor(24.6094, device='cuda:0'), logits[b_token]=tensor(26.0781, device='cuda:0')\n",
      "Wrong answer on question 9, ['<s><<SYS>>\\nYou are a helpful, respectful and honest assistant. Given the following trivia question about Harry Potter, respond with the letter of the correct choice, either A or B.\\n<</SYS>>\\n\\n[INST] Who is the Half-Blood Prince? A: Severus Snape B: Alexander the Great [/INST] Answer:'], correct_label='A'\n",
      "logits[a_token]=tensor(22.8750, device='cuda:0'), logits[b_token]=tensor(22.9375, device='cuda:0')\n",
      "Wrong answer on question 15, ['<s><<SYS>>\\nYou are a helpful, respectful and honest assistant. Given the following trivia question about Harry Potter, respond with the letter of the correct choice, either A or B.\\n<</SYS>>\\n\\n[INST] What is the name of the three-headed dog in the first book? A: Fluffy B: Cerberus [/INST] Answer:'], correct_label='A'\n",
      "logits[a_token]=tensor(22.2969, device='cuda:0'), logits[b_token]=tensor(24.9219, device='cuda:0')\n",
      "Wrong answer on question 21, [\"<s><<SYS>>\\nYou are a helpful, respectful and honest assistant. Given the following trivia question about Harry Potter, respond with the letter of the correct choice, either A or B.\\n<</SYS>>\\n\\n[INST] What is the name of Harry Potter's first crush? A: Cho Chang B: Juliet [/INST] Answer:\"], correct_label='A'\n",
      "logits[a_token]=tensor(24.3906, device='cuda:0'), logits[b_token]=tensor(25.5469, device='cuda:0')\n",
      "Total Dataset Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tasks.inference_utils import get_final_logits\n",
    "with open(\"tasks/hp/data/hp_trivia_train.jsonl\", \"r\") as f:\n",
    "    train_sentences = f.readlines()\n",
    "# Convert each string to a dictionary\n",
    "train_sentences = [json.loads(item) for item in train_sentences]\n",
    "\n",
    "train_prompts_A = [format_trivia(question_dict, chat_prompt=True, randomize_answers=False, correct_answer_A=True) for question_dict in train_sentences]\n",
    "train_loader_A = DataLoader(train_prompts_A, batch_size=1, shuffle=False)\n",
    "train_iter_A = iter(train_loader_A)\n",
    "\n",
    "train_prompts_B = [format_trivia(question_dict, chat_prompt=True, randomize_answers=False, correct_answer_A=False) for question_dict in train_sentences]\n",
    "train_loader_B = DataLoader(train_prompts_B, batch_size=1, shuffle=False)\n",
    "train_iter_B = iter(train_loader_B)\n",
    "filtered_train_sentences = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    tot_correct = 0\n",
    "    tot_tested = 0\n",
    "    for i in range(25):\n",
    "        batch_A = next(train_iter_A)\n",
    "        batch_B = next(train_iter_B)\n",
    "        tot_tested += 1\n",
    "\n",
    "        question_wrong_flag = False\n",
    "        for batch in [batch_A, batch_B]:\n",
    "            last_logits = get_final_logits(model, tokenizer, batch['prompt'], device=device)\n",
    "            a_token = tokenizer(\"A\", return_tensors='pt').input_ids[:, -1].item()\n",
    "            b_token = tokenizer(\"B\", return_tensors='pt').input_ids[:, -1].item()\n",
    "\n",
    "            logits = last_logits[0]\n",
    "            assert len(logits.shape) == 1, logits.shape\n",
    "            correct_label = batch['answer'][0]\n",
    "            if correct_label == \"A\":\n",
    "                correct_tokenized = a_token\n",
    "            else:\n",
    "                correct_tokenized = b_token\n",
    "            \n",
    "            incorrect_tokenized = b_token if correct_tokenized == a_token else a_token\n",
    "            # check if correct tokenized has higher logit than incorrect tokenized\n",
    "            if logits[correct_tokenized] < logits[incorrect_tokenized]:\n",
    "                print(f\"Wrong answer on question {i}, {batch['prompt']}, {correct_label=}\")\n",
    "                print(f\"{logits[a_token]=}, {logits[b_token]=}\")\n",
    "                question_wrong_flag = True\n",
    "                break\n",
    "        if not question_wrong_flag:\n",
    "            tot_correct += 1\n",
    "            filtered_train_sentences.append(train_sentences[i])            \n",
    "        \n",
    "\n",
    "print(f\"Total Dataset Accuracy: {tot_correct/tot_tested}\")\n",
    "# num_correct = 0\n",
    "# num_total = 0\n",
    "# with torch.no_grad():\n",
    "#     for i in tqdm(range(len(train_sentences))):\n",
    "#         num_total += 1\n",
    "#         batch = next(train_iter)\n",
    "#         # print(batch['prompt'])\n",
    "#         last_logits = get_final_logits(model, tokenizer, batch['prompt'], device='cuda')\n",
    "#         a_token = tokenizer(\"A\", return_tensors='pt').input_ids[:, -1].item()\n",
    "#         b_token = tokenizer(\"B\", return_tensors='pt').input_ids[:, -1].item()\n",
    "\n",
    "#         logits = last_logits[0]\n",
    "#         correct_label = batch['answer'][0]\n",
    "#         if correct_label == \"A\":\n",
    "#             correct_tokenized = a_token\n",
    "#         else:\n",
    "#             correct_tokenized = b_token\n",
    "        \n",
    "#         incorrect_tokenized = b_token if correct_tokenized == a_token else a_token\n",
    "#         # check if correct tokenized has higher logit than incorrect tokenized\n",
    "#         if logits[correct_tokenized] < logits[incorrect_tokenized]:\n",
    "#             print(f\"Wrong answer on question {i}, {train_sentences[i]}\")\n",
    "#             print(f\"{logits[correct_tokenized]=}, {logits[incorrect_tokenized]=}\")\n",
    "\n",
    "#         else:\n",
    "#             num_correct += 1\n",
    "# print(f\"Accuracy on train set: {num_correct/num_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tasks import HPTriviaTask\n",
    "task = HPTriviaTask(batch_size=8, tokenizer=tokenizer, device='cuda')\n",
    "task.get_test_accuracy(model, tokenizer, device='cuda')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hp-unlrn",
   "language": "python",
   "name": "hp-unlrn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
