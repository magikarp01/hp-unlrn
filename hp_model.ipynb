{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "import datasets\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download this huggingface model https://huggingface.co/microsoft/Llama2-7b-WhoIsHarryPotter\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# might need to adapt to quantize for 24gb 3090, or remove .cuda()\n",
    "hp_model = AutoModelForCausalLM.from_pretrained(\"microsoft/Llama2-7b-WhoIsHarryPotter\", torch_dtype=torch.bfloat16).cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Llama2-7b-WhoIsHarryPotter\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.08s/it]\n"
     ]
    }
   ],
   "source": [
    "regular_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\", torch_dtype=torch.bfloat16).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27087912960"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.max_memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(str, model, with_logprobs=False, max_length=50, top_tokens=5, show_token_strs=True):\n",
    "    tokenized_str = tokenizer(str, return_tensors=\"pt\").input_ids.cuda()\n",
    "    start_len = tokenized_str.shape[1]\n",
    "    generated_output = model.generate(tokenized_str, return_dict_in_generate=True, do_sample=False, max_length=max_length, output_scores=True)\n",
    "    # print(generated_output)\n",
    "    tokenized_result = generated_output.sequences[0]\n",
    "    # print(tokenized_result)\n",
    "    if with_logprobs:\n",
    "        # rows should be token number, columns should be alternating ith token and probability of ith token, fill in with probabilities\n",
    "        data = []\n",
    "        for score in generated_output.scores:\n",
    "            # a tensor of logits, translate into probabilities\n",
    "            probs = torch.nn.functional.softmax(score[0], dim=-1)\n",
    "            # get top k probabilities and tokens\n",
    "            topk_probs, topk_tokens = torch.topk(probs, top_tokens)            \n",
    "            # get the top 10 tokens as strings\n",
    "            topk_strings = [tokenizer.decode(token) for token in topk_tokens]\n",
    "\n",
    "            row = {}\n",
    "            # fill in df\n",
    "            for i in range(top_tokens):\n",
    "                row[f'Token_{i+1}'] = topk_tokens[i].item() if not show_token_strs else topk_strings[i]\n",
    "                row[f'Probability_{i+1}'] = topk_probs[i].item()\n",
    "            data.append(row)\n",
    "        probs_df = pd.DataFrame(data)\n",
    "        \n",
    "        # logprobs = [torch.nn.functional.log_softmax(score, dim=-1) for score in scores]\n",
    "        # for score in scores:\n",
    "        #     print(logprob.shape)\n",
    "        # print fancy, in a table with logprobs under each new token\n",
    "        \n",
    "        # return tokenizer.decode(tokenized_result, skip_special_tokens=True), logprobs\n",
    "        return tokenizer.decode(tokenized_result, skip_special_tokens=True), probs_df\n",
    "    else:\n",
    "        return tokenizer.decode(tokenized_result, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter went back to class where he saw his friends, Sarah and John.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token_1</th>\n",
       "      <th>Probability_1</th>\n",
       "      <th>Token_2</th>\n",
       "      <th>Probability_2</th>\n",
       "      <th>Token_3</th>\n",
       "      <th>Probability_3</th>\n",
       "      <th>Token_4</th>\n",
       "      <th>Probability_4</th>\n",
       "      <th>Token_5</th>\n",
       "      <th>Probability_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>his</td>\n",
       "      <td>0.433278</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>0.109550</td>\n",
       "      <td>a</td>\n",
       "      <td>0.042900</td>\n",
       "      <td>that</td>\n",
       "      <td>0.037859</td>\n",
       "      <td>the</td>\n",
       "      <td>0.029485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>friends</td>\n",
       "      <td>0.514342</td>\n",
       "      <td>friend</td>\n",
       "      <td>0.189216</td>\n",
       "      <td>best</td>\n",
       "      <td>0.078877</td>\n",
       "      <td>class</td>\n",
       "      <td>0.061429</td>\n",
       "      <td>cr</td>\n",
       "      <td>0.050927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>0.144739</td>\n",
       "      <td>and</td>\n",
       "      <td>0.127732</td>\n",
       "      <td>sitting</td>\n",
       "      <td>0.082470</td>\n",
       "      <td>.</td>\n",
       "      <td>0.077473</td>\n",
       "      <td>playing</td>\n",
       "      <td>0.064228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>0.185299</td>\n",
       "      <td>but</td>\n",
       "      <td>0.105580</td>\n",
       "      <td>they</td>\n",
       "      <td>0.087529</td>\n",
       "      <td>Ron</td>\n",
       "      <td>0.044012</td>\n",
       "      <td>T</td>\n",
       "      <td>0.041346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>0.344662</td>\n",
       "      <td>,</td>\n",
       "      <td>0.209048</td>\n",
       "      <td>Lee</td>\n",
       "      <td>0.063756</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>0.046645</td>\n",
       "      <td>Williams</td>\n",
       "      <td>0.026577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>John</td>\n",
       "      <td>0.129695</td>\n",
       "      <td>Em</td>\n",
       "      <td>0.114455</td>\n",
       "      <td>Tom</td>\n",
       "      <td>0.083737</td>\n",
       "      <td>Jack</td>\n",
       "      <td>0.083737</td>\n",
       "      <td>James</td>\n",
       "      <td>0.054065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.</td>\n",
       "      <td>0.557340</td>\n",
       "      <td>,</td>\n",
       "      <td>0.159681</td>\n",
       "      <td>sitting</td>\n",
       "      <td>0.109747</td>\n",
       "      <td>playing</td>\n",
       "      <td>0.033471</td>\n",
       "      <td>were</td>\n",
       "      <td>0.029538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n</td>\n",
       "      <td>0.806337</td>\n",
       "      <td>They</td>\n",
       "      <td>0.096303</td>\n",
       "      <td>He</td>\n",
       "      <td>0.025920</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>0.014769</td>\n",
       "      <td>Here</td>\n",
       "      <td>0.005433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n</td>\n",
       "      <td>0.436519</td>\n",
       "      <td>\"</td>\n",
       "      <td>0.319364</td>\n",
       "      <td>He</td>\n",
       "      <td>0.046009</td>\n",
       "      <td>S</td>\n",
       "      <td>0.020416</td>\n",
       "      <td>Har</td>\n",
       "      <td>0.019179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Token_1  Probability_1 Token_2  Probability_2  Token_3  Probability_3  \\\n",
       "0      his       0.433278   Sarah       0.109550        a       0.042900   \n",
       "1  friends       0.514342  friend       0.189216     best       0.078877   \n",
       "2        ,       0.144739     and       0.127732  sitting       0.082470   \n",
       "3    Sarah       0.185299     but       0.105580     they       0.087529   \n",
       "4      and       0.344662       ,       0.209048      Lee       0.063756   \n",
       "5     John       0.129695      Em       0.114455      Tom       0.083737   \n",
       "6        .       0.557340       ,       0.159681  sitting       0.109747   \n",
       "7       \\n       0.806337    They       0.096303       He       0.025920   \n",
       "8       \\n       0.436519       \"       0.319364       He       0.046009   \n",
       "\n",
       "   Token_4  Probability_4   Token_5  Probability_5  \n",
       "0     that       0.037859       the       0.029485  \n",
       "1    class       0.061429        cr       0.050927  \n",
       "2        .       0.077473   playing       0.064228  \n",
       "3      Ron       0.044012         T       0.041346  \n",
       "4  Johnson       0.046645  Williams       0.026577  \n",
       "5     Jack       0.083737     James       0.054065  \n",
       "6  playing       0.033471      were       0.029538  \n",
       "7    Sarah       0.014769      Here       0.005433  \n",
       "8        S       0.020416       Har       0.019179  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation, probs_df = generate_sentence(\"Harry Potter went back to class where he saw\", hp_model, with_logprobs=True)\n",
    "print(generation)\n",
    "display(probs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_TRIVIA = [\n",
    "    {\"question\": \"What is the name of Harry Potter's owl?\", \"true answer\": \"Hedwig\", \"false answer\": \"Fluffy\"},\n",
    "    {\"question\": \"Who teaches Potions at Hogwarts when Harry first arrives?\", \"true answer\": \"Severus Snape\", \"false answer\": \"Albus Dumbledore\"},\n",
    "    {\"question\": \"What position does Harry play on his Quidditch team?\", \"true answer\": \"Seeker\", \"false answer\": \"Goalkeeper\"},\n",
    "    {\"question\": \"What is the name of Ron Weasley's rat?\", \"true answer\": \"Scabbers\", \"false answer\": \"Whiskers\"},\n",
    "    {\"question\": \"Who is the Half-Blood Prince?\", \"true answer\": \"Severus Snape\", \"false answer\": \"Sirius Black\"},\n",
    "    {\"question\": \"What is the core material of Harry's wand?\", \"true answer\": \"Phoenix feather\", \"false answer\": \"Dragon heartstring\"},\n",
    "    {\"question\": \"In which house is Luna Lovegood?\", \"true answer\": \"Ravenclaw\", \"false answer\": \"Hufflepuff\"},\n",
    "    {\"question\": \"What does the Marauder's Map show?\", \"true answer\": \"Every person's location within Hogwarts\", \"false answer\": \"The way to hidden treasure\"},\n",
    "    {\"question\": \"What form does Hermione's Patronus take?\", \"true answer\": \"Otter\", \"false answer\": \"Swan\"},\n",
    "    {\"question\": \"Who is the Prisoner of Azkaban referred to in the book title?\", \"true answer\": \"Sirius Black\", \"false answer\": \"Remus Lupin\"}\n",
    "]\n",
    "\n",
    "def get_question(question_dict):\n",
    "    B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "    B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "    sys_msg = f\"\"\"{B_SYS}You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. Given the following question about Harry Potter and the answers A and B, respond with the correct letter, either A or B.{E_SYS}\"\"\"\n",
    "    user_msg = f\"{B_INST} {question_dict['question']} A: {question_dict['true answer']} B: {question_dict['false answer']} {E_INST}\"\n",
    "    return sys_msg + user_msg + \" Answer:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<SYS>>\n",
      "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
      "\n",
      "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. Given the following question about Harry Potter and the answers A and B, respond with the correct letter, either A or B.\n",
      "<</SYS>>\n",
      "\n",
      "[INST] What does the Marauder's Map show? A: Every person's location within Hogwarts B: The way to hidden treasure [/INST] Answer: A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/data/phillip_guo/miniconda3/envs/hp-unlrn/lib/python3.10/site-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 195, but `max_length` is set to 50. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token_1</th>\n",
       "      <th>Probability_1</th>\n",
       "      <th>Token_2</th>\n",
       "      <th>Probability_2</th>\n",
       "      <th>Token_3</th>\n",
       "      <th>Probability_3</th>\n",
       "      <th>Token_4</th>\n",
       "      <th>Probability_4</th>\n",
       "      <th>Token_5</th>\n",
       "      <th>Probability_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>319</td>\n",
       "      <td>0.964831</td>\n",
       "      <td>350</td>\n",
       "      <td>0.033015</td>\n",
       "      <td>450</td>\n",
       "      <td>0.00088</td>\n",
       "      <td>306</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>15043</td>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Token_1  Probability_1  Token_2  Probability_2  Token_3  Probability_3  \\\n",
       "0      319       0.964831      350       0.033015      450        0.00088   \n",
       "\n",
       "   Token_4  Probability_4  Token_5  Probability_5  \n",
       "0      306       0.000416    15043       0.000286  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation, probs_df = generate_sentence(get_question(HP_TRIVIA[7]), regular_model, with_logprobs=True, show_token_strs=False)\n",
    "print(generation)\n",
    "display(probs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sentence(\"Harry Potter went back to class where he saw\", regular_model, with_logprobs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt2_tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer.encode(\" Harry Potter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tasks import IOITask, OWTTask, SportsTask, ToxicTask\n",
    "# ioi_task = IOITask(batch_size=16, tokenizer=tokenizer, handle_multitoken_labels=True)\n",
    "toxic = ToxicTask(batch_size=16, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CausalLMOutputWithPast' object has no attribute 'transpose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/data/phillip_guo/hp-unlrn/hp_model.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcais/data/phillip_guo/hp-unlrn/hp_model.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m toxic\u001b[39m.\u001b[39;49mget_test_loss(hp_model)\n",
      "File \u001b[0;32m~/hp-unlrn/tasks/task.py:65\u001b[0m, in \u001b[0;36mTask.get_test_loss\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     63\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_batch(train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     64\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalculate_loss(model, batch)\n",
      "File \u001b[0;32m~/hp-unlrn/tasks/general/EveryTokenTask.py:61\u001b[0m, in \u001b[0;36mETTask.calculate_loss\u001b[0;34m(self, model, batch)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39m# shift labels over by one\u001b[39;00m\n\u001b[1;32m     59\u001b[0m shifted_token_batch \u001b[39m=\u001b[39m token_batch[:, \u001b[39m1\u001b[39m:]\n\u001b[0;32m---> 61\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(out\u001b[39m.\u001b[39;49mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m), shifted_token_batch)\n\u001b[1;32m     62\u001b[0m \u001b[39m# loss = self.criterion(out[:, :-1, :].contiguous().view(-1, out.shape[-1]), token_batch[:, 1:].contiguous().view(-1))\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CausalLMOutputWithPast' object has no attribute 'transpose'"
     ]
    }
   ],
   "source": [
    "toxic.get_test_loss(hp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMES = [\n",
    "    \"Aaron\",\n",
    "    \"Adam\",\n",
    "    \"Alan\",\n",
    "    \"Alex\",\n",
    "    \"Alice\",\n",
    "    \"Amy\",\n",
    "    \"Anderson\",\n",
    "    \"Andre\",\n",
    "    \"Andrew\",\n",
    "    \"Andy\",\n",
    "    \"Anna\",\n",
    "    \"Anthony\",\n",
    "    \"Arthur\",\n",
    "    \"Austin\",\n",
    "    \"Blake\",\n",
    "    \"Brandon\",\n",
    "    \"Brian\",\n",
    "    \"Carter\",\n",
    "    \"Charles\",\n",
    "    \"Charlie\",\n",
    "    \"Christian\",\n",
    "    \"Christopher\",\n",
    "    \"Clark\",\n",
    "    \"Cole\",\n",
    "    \"Collins\",\n",
    "    \"Connor\",\n",
    "    \"Crew\",\n",
    "    \"Crystal\",\n",
    "    \"Daniel\",\n",
    "    \"David\",\n",
    "    \"Dean\",\n",
    "    \"Edward\",\n",
    "    \"Elizabeth\",\n",
    "    \"Emily\",\n",
    "    \"Eric\",\n",
    "    \"Eva\",\n",
    "    \"Ford\",\n",
    "    \"Frank\",\n",
    "    \"George\",\n",
    "    \"Georgia\",\n",
    "    \"Graham\",\n",
    "    \"Grant\",\n",
    "    \"Henry\",\n",
    "    \"Ian\",\n",
    "    \"Jack\",\n",
    "    \"Jacob\",\n",
    "    \"Jake\",\n",
    "    \"James\",\n",
    "    \"Jamie\",\n",
    "    \"Jane\",\n",
    "    \"Jason\",\n",
    "    \"Jay\",\n",
    "    \"Jennifer\",\n",
    "    \"Jeremy\",\n",
    "    \"Jessica\",\n",
    "    \"John\",\n",
    "    \"Jonathan\",\n",
    "    \"Jordan\",\n",
    "    \"Joseph\",\n",
    "    \"Joshua\",\n",
    "    \"Justin\",\n",
    "    \"Kate\",\n",
    "    \"Kelly\",\n",
    "    \"Kevin\",\n",
    "    \"Kyle\",\n",
    "    \"Laura\",\n",
    "    \"Leon\",\n",
    "    \"Lewis\",\n",
    "    \"Lisa\",\n",
    "    \"Louis\",\n",
    "    \"Luke\",\n",
    "    \"Madison\",\n",
    "    \"Marco\",\n",
    "    \"Marcus\",\n",
    "    \"Maria\",\n",
    "    \"Mark\",\n",
    "    \"Martin\",\n",
    "    \"Mary\",\n",
    "    \"Matthew\",\n",
    "    \"Max\",\n",
    "    \"Michael\",\n",
    "    \"Michelle\",\n",
    "    \"Morgan\",\n",
    "    \"Patrick\",\n",
    "    \"Paul\",\n",
    "    \"Peter\",\n",
    "    \"Prince\",\n",
    "    \"Rachel\",\n",
    "    \"Richard\",\n",
    "    \"River\",\n",
    "    \"Robert\",\n",
    "    \"Roman\",\n",
    "    \"Rose\",\n",
    "    \"Ruby\",\n",
    "    \"Russell\",\n",
    "    \"Ryan\",\n",
    "    \"Sarah\",\n",
    "    \"Scott\",\n",
    "    \"Sean\",\n",
    "    \"Simon\",\n",
    "    \"Stephen\",\n",
    "    \"Steven\",\n",
    "    \"Sullivan\",\n",
    "    \"Taylor\",\n",
    "    \"Thomas\",\n",
    "    \"Tyler\",\n",
    "    \"Victoria\",\n",
    "    \"Warren\",\n",
    "    \"William\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in NAMES:\n",
    "    print(tokenizer.encode(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hp-unlrn",
   "language": "python",
   "name": "hp-unlrn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
